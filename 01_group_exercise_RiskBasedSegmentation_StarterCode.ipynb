{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Project - Risk Based Segmentation \n",
    "\n",
    "This is document contains a description of the task and also a starter code. \n",
    "Implement your exercise by changing only this Jupyter Notebook and the class inside RiskDataFrame.py, deliver both files. \n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Customer segmentation involves categorizing the portfolio by industry, location, revenue, account size, and number of employees and many other variables to reveal where risk and opportunity live within the portfolio. Those patterns can then provide key measurable data points for more predictive credit risk management. Taking a portfolio approach to risk management gives credit professionals a better fix on the accounts, in order to develop strategies for better serving segments that present the best opportunities. Not only that, you can work to maximize performance\n",
    "in all customer segments, even seemingly risky segments.\n",
    "\n",
    "Customer segmentation analysis can lead to several tangible improvements in credit risk management: stronger credit policies, and improved internal communication and cooperation across teams.\n",
    "\n",
    "## Task scope\n",
    "Your group is working in the retail risk modeling team and you are asked to build a class to perform risk-based segmentation and test it for car loansâ€™ customers based on given historical data of customer behavior. The class must perform the segmentation from a risk management perspective.\n",
    "\n",
    "## Class\n",
    "We will use Nico's great initial code, which extends Pandas DataFrame in a magical way turning our own class into like-Pandas:\n",
    "\n",
    "    #Initializing the inherited pd.DataFrame\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args,**kwargs)\n",
    "    \n",
    "    @property\n",
    "    def _constructor(self):\n",
    "        def func_(*args,**kwargs):\n",
    "            df = RiskDataframe(*args,**kwargs)\n",
    "            return df\n",
    "        return func_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PERFORM YOUR OWN DATA CLEANNING & DATA PREPARATION HERE\n",
    "\n",
    "Your objective in this part is simply to prepare the data to apply to the missing_not_at_random and find_segment_split\n",
    "methods. Do not overcomplicate the data cleanning and data preparation. Keep it simple!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38386, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of use\n",
    "import pandas as pd\n",
    "import RiskDataframe as rdf\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "dataframe = pd.read_csv(\"AUTO_LOANS_DATA.csv\", sep=\";\")\n",
    "dataframe['BINARIZED_TARGET'] = dataframe['BUCKET'].apply(lambda x: 1 if x>0 else 0)\n",
    "\n",
    "# PERFORM YOUR OWN DATA CLEANNING & DATA PREPARATION HERE - START!\n",
    "# Use any data cleanning / data preparation from individual project / it won't be assessed here)!\n",
    "dataframe = dataframe[dataframe['PROGRAM_NAME'].str.contains(\"Corporate\")==False]    \n",
    "dataframe.sort_values(by=['LOAN_OPEN_DATE'])\n",
    "dataframe.drop_duplicates('CUSTOMER_ID', keep = 'last', inplace = True)\n",
    "dataframe.drop('ACCOUNT_NUMBER', inplace=True, axis=1)\n",
    "dataframe.drop('CUSTOMER_ID', inplace=True, axis=1)\n",
    "dataframe.drop('BUCKET', inplace=True, axis=1)\n",
    "# PERFORM YOUR OWN DATA CLEANNING HERE  - END!\n",
    "\n",
    "myrdf = rdf.RiskDataframe(dataframe)\n",
    "myrdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['REPORTING_DATE', 'PROGRAM_NAME', 'LOAN_OPEN_DATE',\n",
       "       'EXPECTED_CLOSE_DATE', 'ORIGINAL_BOOKED_AMOUNT', 'OUTSTANDING', 'SEX',\n",
       "       'CUSTOMER_OPEN_DATE', 'BIRTH_DATE', 'PROFESSION', 'CAR_TYPE',\n",
       "       'BINARIZED_TARGET'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REPORTING_DATE             object\n",
       "PROGRAM_NAME               object\n",
       "LOAN_OPEN_DATE             object\n",
       "EXPECTED_CLOSE_DATE        object\n",
       "ORIGINAL_BOOKED_AMOUNT    float64\n",
       "OUTSTANDING               float64\n",
       "SEX                        object\n",
       "CUSTOMER_OPEN_DATE         object\n",
       "BIRTH_DATE                 object\n",
       "PROFESSION                 object\n",
       "CAR_TYPE                   object\n",
       "BINARIZED_TARGET            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the types\n",
    "\n",
    "Make sure you use it inside the methods if you need this information, if you already transformed the data update this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REPORTING_DATE            datetime64[ns]\n",
       "PROGRAM_NAME                    category\n",
       "LOAN_OPEN_DATE            datetime64[ns]\n",
       "EXPECTED_CLOSE_DATE       datetime64[ns]\n",
       "ORIGINAL_BOOKED_AMOUNT           float64\n",
       "OUTSTANDING                      float64\n",
       "SEX                             category\n",
       "CUSTOMER_OPEN_DATE        datetime64[ns]\n",
       "BIRTH_DATE                datetime64[ns]\n",
       "PROFESSION                      category\n",
       "CAR_TYPE                        category\n",
       "BINARIZED_TARGET                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting the types\n",
    "argument_dict = {'REPORTING_DATE':'datetime64[ns]','LOAN_OPEN_DATE':'datetime64[ns]',\n",
    "                 'EXPECTED_CLOSE_DATE':'datetime64[ns]','CUSTOMER_OPEN_DATE':'datetime64[ns]',\n",
    "                 'BIRTH_DATE':'datetime64[ns]','PROGRAM_NAME':'category','SEX':'category',\n",
    "                'PROFESSION':'category','CAR_TYPE':'category'}\n",
    "myrdf.SetAttributes(argument_dict)\n",
    "myrdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Implement the following 2 methods to automate the Risk-based segmentation process:\n",
    "* You can implement more methods if you think it is necessary.\n",
    "* In computer science, when we are dividing the code it is important to think which code does what. For example, __data cleanning__ and __data preparation__, is it done by the Risk Based Segmentation Class or the class assumes that the data is clean and ready for modelling (all variables are numeric, and dummies are already provided)?\n",
    "* Use: the input dataset should already be clean and ready for the trainning of a Logistic Regression with a binary target 0 and 1 class. \n",
    "* Scope: data cleanning and data preparation is out of the scope of the Class, but notice that .missing_not_at_random() requires the data to have missing values.\n",
    "\n",
    "## 1) Implement a method .missing_not_at_random() \n",
    "To identify different potential segments sharing data (based on sharing missing values) - Expected result is a print:\n",
    "Missing Not At Random Repport (MNAR) -  PROFESSION, SEX and BIRTH_DATE variables seem Missing Not at Random, there for we recommend:\n",
    "\n",
    "&emsp;  Thin File Segment Variables (all others variables free of MNAR issue): REPORTING_DATE, ACCOUNT_NUMBER, CUSTOMER_ID, PROGRAM_NAME, LOAN_OPEN_DATE, EXPECTED_CLOSE_DATE, ORIGINAL_BOOKED_AMOUNT, \n",
    "OUTSTANDING, CUSTOMER_OPEN_DATE, CAR_TYPE\n",
    "\n",
    "&emsp; Full File Segment Variables: REPORTING_DATE, ACCOUNT_NUMBER, CUSTOMER_ID, PROGRAM_NAME, LOAN_OPEN_DATE, EXPECTED_CLOSE_DATE, ORIGINAL_BOOKED_AMOUNT, OUTSTANDING, SEX, CUSTOMER_OPEN_DATE, BIRTH_DATE, PROFESSION, CAR_TYPE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To be implemented.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf.missing_not_at_random(input_vars=[]) # If input_vars == [] use all varibles of the df, \n",
    "                                           # otherwise only use the variables informed in the input_vars list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "OUTPUT SAMPLE:\n",
    "\n",
    "__Missing Not At Random Repport__ -  REPORTING_DATE, ACCOUNT_NUMBER, CUSTOMER_ID variables seem Missing Not at Random, there for we recommend:\n",
    "\n",
    "&emsp;  Thin File Segment Variables: PROGRAM_NAME, LOAN_OPEN_DATE, EXPECTED_CLOSE_DATE, \n",
    "ORIGINAL_BOOKED_AMOUNT, OUTSTANDING, SEX, \n",
    "CUSTOMER_OPEN_DATE, BIRTH_DATE, PROFESSION, CAR_TYPE\n",
    "\n",
    "&emsp; Full File Segment Variables: REPORTING_DATE, ACCOUNT_NUMBER, CUSTOMER_ID, PROGRAM_NAME, LOAN_OPEN_DATE, EXPECTED_CLOSE_DATE, ORIGINAL_BOOKED_AMOUNT, \n",
    "OUTSTANDING, SEX, CUSTOMER_OPEN_DATE, BIRTH_DATE, PROFESSION, CAR_TYPE\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\t2) implement a method .find_segment_split(variable)\n",
    "given one variable, implement a method to identify if the variable is a good segmentation splitter and if the variable is a good splitter,   \n",
    "different segments of customers with different level of risk (the one explained in the second video)\n",
    "* Scope: data cleanning and data preparation is out of the scope of the Class, note that .find_segment_split(VARIABLE) assumes the data is already clean free of missing values.\n",
    "* Categorical: for the segmentation process of categorical variable, dummy transformation is not practical, it is recommended that categorical variables come pre-transformed into numerical by replacing the categories by the Probability of belonging to class 1.\n",
    "* The following code only works for a single variable, implement a loop going over each variable of the dataset as a candidate for segmentation.\n",
    "* The following method must implement two segmentation approaches, one for Categorical Nominal (order not relevant - variable must be automatically transformed) and others where order is important.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To be implemented.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrdf.find_segment_split(canditate='SEX', # If the candidate variable is Nominal, in the class transform \n",
    "                                          # into probability of class 1 before performing the segmentation algorithm.\n",
    "                         input_vars=['ORIGINAL_BOOKED_AMOUNT', 'OUTSTANDING'],  # List of input variables ready for \n",
    "                                                                                # Logistic Regression, dates and \n",
    "                                                                                # text must be transformed before \n",
    "                                                                                # invoking the method.   \n",
    "                         target='BINARIZED_TARGET') # The target variable must be 0 or 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    "\n",
    "## Mandatory (part 1 - p1) -  Implement the following: (5 out of 10 points)\n",
    "\n",
    "- __Project Name__: pick a name for your project (if it is taken at https://pypi.org/ please create small variations), I recommend you get inspiration by the following Pockemon names: some_pockemon_examples.zip\n",
    "\n",
    "- __Project Managment (Github)__: Work in group using Github, invite professor manoelgad@gmail.com as a collaborator to your project from the very beggining.\n",
    "\n",
    "- __Implementation__: Discuss in group and decide the implementation you need to do for each method (missing_not_at_random and find_segment_split), then do the implementation of missing_not_at_random and find_segment_split. Your implementation should work in any dataset (make the necessary assumption and inform the user if the assumption are not followed, for example: inform the dataset must be clean and types must be informed in case they are not). \n",
    "\n",
    "- __Video__: Create a video from 5 to 15 minutes explainning the whole library (including p1 and p2) and showing examples of how to use it. The video will not be assessed own its own and won't be assessed by colleagues. The video can be very simple, just the notebook/python class and someone explainning things. Upload the video to Youtube and include a link to the video in the website if your group decide to pick Publishing below.    \n",
    "\n",
    "\n",
    "## Improvements (part 2 - p2) -  Implement 2 of the following list of tasks:  (5 out of 10 points)\n",
    "\n",
    "- __Improving__: Make improvements to the code -  Reliable/Robust: Create a train-test split, train all models in train and test all models always in test; Robust: Research and apply a statistical test to decide when the accuracy diffrence in statiscally relevant. Small functions/methods: Break your implementation into small functions/methods; Fast: Optimize your code, use vectorization when possible. Use stratified random sampling to reduce dataset sizes and therefore speed up the segmentation process. Implement segmentation split using Tree algorithm.\n",
    "\n",
    "- __Publishing__: Publish your code in GitHub -  Work in group using Github, invite professor manoelgad@gmail.com as a collaborator to your project from the very beggining. Create a python package and distribute your package using https://pypi.org/, by the end of the project one must be able to pip install your project and use it.\n",
    "References: https://www.youtube.com/watch?v=GIF3LaRqgXo; and  https://github.com/judy2k/publishing_python_packages_talk\n",
    "\n",
    "- __Testing__: Implement a Test class using unittest with an \"comprehensive\" set of tests using a series of datasets of your choice. Have a look at this: https://ains.co/blog/things-which-arent-magic-flask-part-1.html and https://www.youtube.com/watch?v=1Lfv5tUGsn8\n",
    "\n",
    "- __Documentation__: create a documentation for your project and publish it at GitHub project (readme) and also a pythonanywhere.com website (simple HTML). The documentation must contain an about, a how to and also examples of how to use with one or more datasets. All used datasets should be provided within the project (make sure you don't share huge datasets, make it small before sharing your code).\n",
    "\n",
    "- __Logging & Repporting__: Log all intermediate results and final results into a Sqlite database using SQLAlchemy, then produce the final result repport in HTML format using Bokeh.\n",
    "\n",
    "\n",
    "# Evaluation criteria\n",
    "\n",
    "All team members have the choice of focusing, by choising 1 or 2 of the tasks of part 2.\n",
    "*   If 1 task of part 2 is choosen, grade will be: p1\\*0.5 + p2x\\*0.4 + (p2y\\*0.1) (p2x is the grade in the choosen task and p2y the other) \n",
    "*   If 2 tasks of part 2 are choosen, grade will be: p1\\*0.5 + (p2x\\*0.25 + p2y\\*0.25)\n",
    "* If your group only implement 1 extra part, all members will be assessed using: p1\\*0.5 + p2x\\*0.4 + (p2y\\*0.1)\n",
    "* If your group implements more then 2 parts, please indicate the ones you want to be assessed upon.\n",
    "\n",
    "\n",
    "What professor will look at when assessing the project:\n",
    "*\tProblem structuring - How did you structure the problem and the project?\n",
    "*\tWhat assumptions did you make? (Please mention them in the video)\n",
    "*\tHow did you narrow the scope? (Please mention them in the video)\n",
    "*\tTechnical Skills: How reliable (does it use your own class? does is it apply data quality controls?)), readable and flexible (can you apply your code to a new dataset?) was the code that you developed?\n",
    "* Analytical Skills: How logically sound, complete and meaningful was the approach (machine learning, statistics, analytics, visualizationâ€¦) that you applied?\n",
    "*\tUsefulness:\tHow useful would the results of your work for new datasets?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools\n",
    "You are allowed to use __Python only__ and any Python Library inside your Jupyter Notebook or inside your Class, always give preference to Pandas and Scikit Learn whenever you can.\n",
    "\n",
    "\n",
    "\n",
    "# Deliverables\n",
    "*\tA zip file with all code and datasets used for the projet.\n",
    "\n",
    "\n",
    "# Data description\n",
    "We will provide you with historical data of car loans. The data contains monthly status for each loan for 3 years. In addition to some demographic information\n",
    "\n",
    "# Notes:\n",
    "*\tThis data is Loan level NOT Customer level, meaning that one customer can take more than one loan\n",
    "*\tThe data is monthly starting from 2016-01-01 to 2019-09-01 so if the loan already started before Jan2016 you will find partial history for it.\n",
    "*\tWe have multiple programs under the car loans product\n",
    "*\tMake sure you understand the difference between Buckets\n",
    "\n",
    "# Research:\n",
    "In order to implement the methods missing_not_at_random and find_segment_split, you are allowed to search for whichever information you need in the internet including but not limited to:\n",
    "*\tCode syntax\n",
    "*\tBusiness term (However you can ask me)\n",
    "\n",
    "Start by looking into these 3 videos:\n",
    "*\tWhat is Risk-based segmentation? https://www.youtube.com/watch?v=2ZpLgUcucfQ \n",
    "*   This is a generic video on Segmentation, it is a good reference, but careful not all needs to be implemented and not all mentioned here is relevant for this project: https://www.youtube.com/watch?v=PLsUfDDytaE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX: \n",
    "\n",
    "## Simple example of Risk Based Segmentation\n",
    "\n",
    "*   Video explainning the code below: https://www.youtube.com/watch?v=kWtnlpGwh_o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataframe#pd.read_csv(\"AUTO_LOANS_DATA.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argument_dict = {'REPORTING_DATE':'datetime64[ns]','LOAN_OPEN_DATE':'datetime64[ns]',\n",
    "                 'EXPECTED_CLOSE_DATE':'datetime64[ns]','CUSTOMER_OPEN_DATE':'datetime64[ns]',\n",
    "                 'BIRTH_DATE':'datetime64[ns]','PROGRAM_NAME':'category','BUCKET':'category','SEX':'category',\n",
    "                'PROFESSION':'category','CAR_TYPE':'category'}\n",
    "myrdf.SetAttributes(argument_dict)\n",
    "myrdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Sample trick to speed up the process..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = dataframe\n",
    "df_random_sample, _ = train_test_split(dataframe, test_size=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_random_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REPORTING_DATE</th>\n",
       "      <th>PROGRAM_NAME</th>\n",
       "      <th>LOAN_OPEN_DATE</th>\n",
       "      <th>EXPECTED_CLOSE_DATE</th>\n",
       "      <th>ORIGINAL_BOOKED_AMOUNT</th>\n",
       "      <th>OUTSTANDING</th>\n",
       "      <th>SEX</th>\n",
       "      <th>CUSTOMER_OPEN_DATE</th>\n",
       "      <th>BIRTH_DATE</th>\n",
       "      <th>PROFESSION</th>\n",
       "      <th>CAR_TYPE</th>\n",
       "      <th>BINARIZED_TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>893110</th>\n",
       "      <td>2019-08-29</td>\n",
       "      <td>Auto Loans 50% Down Payment - Employed</td>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>2024-09-03</td>\n",
       "      <td>288750.0</td>\n",
       "      <td>290097.50</td>\n",
       "      <td>M</td>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>1974-01-17</td>\n",
       "      <td>Company Owner</td>\n",
       "      <td>HYUNDAI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564178</th>\n",
       "      <td>2018-02-28</td>\n",
       "      <td>Auto Loans 50% Down Payment - Self Employed</td>\n",
       "      <td>2015-02-09</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>F</td>\n",
       "      <td>2010-08-09</td>\n",
       "      <td>1971-01-03</td>\n",
       "      <td>HOUSEWIFE</td>\n",
       "      <td>Saipa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888003</th>\n",
       "      <td>2019-08-29</td>\n",
       "      <td>Auto Loans 40% Down Payment - Employed</td>\n",
       "      <td>2016-09-26</td>\n",
       "      <td>2023-09-03</td>\n",
       "      <td>70200.0</td>\n",
       "      <td>50953.96</td>\n",
       "      <td>M</td>\n",
       "      <td>2016-09-06</td>\n",
       "      <td>1974-01-26</td>\n",
       "      <td>Manager</td>\n",
       "      <td>HYUNDAI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257509</th>\n",
       "      <td>2016-11-30</td>\n",
       "      <td>Auto Loans 30% Down Payment - Self Employed</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>2023-05-03</td>\n",
       "      <td>129500.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>M</td>\n",
       "      <td>2016-04-19</td>\n",
       "      <td>1988-03-10</td>\n",
       "      <td>Company Owner</td>\n",
       "      <td>HYUNDAI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896560</th>\n",
       "      <td>2019-08-29</td>\n",
       "      <td>Auto Loans 30% Down Payment - Employed</td>\n",
       "      <td>2015-06-11</td>\n",
       "      <td>2020-08-03</td>\n",
       "      <td>72730.0</td>\n",
       "      <td>22819.58</td>\n",
       "      <td>F</td>\n",
       "      <td>2015-03-05</td>\n",
       "      <td>1978-10-04</td>\n",
       "      <td>Manager</td>\n",
       "      <td>SUZUKI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895386</th>\n",
       "      <td>2019-08-29</td>\n",
       "      <td>Pick Up and Small Trucks</td>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>2020-12-03</td>\n",
       "      <td>170400.0</td>\n",
       "      <td>117036.06</td>\n",
       "      <td>M</td>\n",
       "      <td>2018-10-30</td>\n",
       "      <td>1962-04-10</td>\n",
       "      <td>Business Man / Trader</td>\n",
       "      <td>CHEVROLET</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168544</th>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>Auto Loans 50% Down Payment - Self Employed</td>\n",
       "      <td>2014-10-02</td>\n",
       "      <td>2016-09-03</td>\n",
       "      <td>43500.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>M</td>\n",
       "      <td>2014-09-11</td>\n",
       "      <td>1969-09-04</td>\n",
       "      <td>Company Owner</td>\n",
       "      <td>GELY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897636</th>\n",
       "      <td>2019-08-29</td>\n",
       "      <td>Auto Loans 40% Down Payment - Employed</td>\n",
       "      <td>2017-07-16</td>\n",
       "      <td>2020-06-03</td>\n",
       "      <td>92400.0</td>\n",
       "      <td>32455.49</td>\n",
       "      <td>M</td>\n",
       "      <td>2017-07-10</td>\n",
       "      <td>1988-03-01</td>\n",
       "      <td>Athletes</td>\n",
       "      <td>BYD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452927</th>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>Auto Loans 50% Down Payment - Self Employed</td>\n",
       "      <td>2014-09-30</td>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>5248.05</td>\n",
       "      <td>F</td>\n",
       "      <td>2014-09-22</td>\n",
       "      <td>1972-08-02</td>\n",
       "      <td>HOUSEWIFE</td>\n",
       "      <td>HYUNDAI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448543</th>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>Auto Loans 30% Down Payment - Employed</td>\n",
       "      <td>2014-04-01</td>\n",
       "      <td>2019-05-03</td>\n",
       "      <td>30450.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>M</td>\n",
       "      <td>2014-03-12</td>\n",
       "      <td>1983-05-10</td>\n",
       "      <td>Accountant - Employee</td>\n",
       "      <td>SUZUKI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1919 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       REPORTING_DATE                                 PROGRAM_NAME  \\\n",
       "893110     2019-08-29       Auto Loans 50% Down Payment - Employed   \n",
       "564178     2018-02-28  Auto Loans 50% Down Payment - Self Employed   \n",
       "888003     2019-08-29       Auto Loans 40% Down Payment - Employed   \n",
       "257509     2016-11-30  Auto Loans 30% Down Payment - Self Employed   \n",
       "896560     2019-08-29       Auto Loans 30% Down Payment - Employed   \n",
       "...               ...                                          ...   \n",
       "895386     2019-08-29                     Pick Up and Small Trucks   \n",
       "168544     2016-08-31  Auto Loans 50% Down Payment - Self Employed   \n",
       "897636     2019-08-29       Auto Loans 40% Down Payment - Employed   \n",
       "452927     2017-07-31  Auto Loans 50% Down Payment - Self Employed   \n",
       "448543     2017-07-31       Auto Loans 30% Down Payment - Employed   \n",
       "\n",
       "       LOAN_OPEN_DATE EXPECTED_CLOSE_DATE  ORIGINAL_BOOKED_AMOUNT  \\\n",
       "893110     2019-08-26          2024-09-03                288750.0   \n",
       "564178     2015-02-09          2020-02-03                 30000.0   \n",
       "888003     2016-09-26          2023-09-03                 70200.0   \n",
       "257509     2016-04-24          2023-05-03                129500.0   \n",
       "896560     2015-06-11          2020-08-03                 72730.0   \n",
       "...               ...                 ...                     ...   \n",
       "895386     2018-11-19          2020-12-03                170400.0   \n",
       "168544     2014-10-02          2016-09-03                 43500.0   \n",
       "897636     2017-07-16          2020-06-03                 92400.0   \n",
       "452927     2014-09-30          2017-10-03                 49500.0   \n",
       "448543     2014-04-01          2019-05-03                 30450.0   \n",
       "\n",
       "        OUTSTANDING SEX CUSTOMER_OPEN_DATE BIRTH_DATE             PROFESSION  \\\n",
       "893110    290097.50   M         2019-07-30 1974-01-17          Company Owner   \n",
       "564178         0.00   F         2010-08-09 1971-01-03              HOUSEWIFE   \n",
       "888003     50953.96   M         2016-09-06 1974-01-26                Manager   \n",
       "257509         0.00   M         2016-04-19 1988-03-10          Company Owner   \n",
       "896560     22819.58   F         2015-03-05 1978-10-04                Manager   \n",
       "...             ...  ..                ...        ...                    ...   \n",
       "895386    117036.06   M         2018-10-30 1962-04-10  Business Man / Trader   \n",
       "168544         0.00   M         2014-09-11 1969-09-04          Company Owner   \n",
       "897636     32455.49   M         2017-07-10 1988-03-01               Athletes   \n",
       "452927      5248.05   F         2014-09-22 1972-08-02              HOUSEWIFE   \n",
       "448543         0.00   M         2014-03-12 1983-05-10  Accountant - Employee   \n",
       "\n",
       "         CAR_TYPE  BINARIZED_TARGET  \n",
       "893110    HYUNDAI                 0  \n",
       "564178      Saipa                 0  \n",
       "888003    HYUNDAI                 0  \n",
       "257509    HYUNDAI                 0  \n",
       "896560     SUZUKI                 1  \n",
       "...           ...               ...  \n",
       "895386  CHEVROLET                 0  \n",
       "168544       GELY                 0  \n",
       "897636        BYD                 0  \n",
       "452927    HYUNDAI                 0  \n",
       "448543     SUZUKI                 0  \n",
       "\n",
       "[1919 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REPORTING_DATE</th>\n",
       "      <th>PROGRAM_NAME</th>\n",
       "      <th>LOAN_OPEN_DATE</th>\n",
       "      <th>EXPECTED_CLOSE_DATE</th>\n",
       "      <th>ORIGINAL_BOOKED_AMOUNT</th>\n",
       "      <th>OUTSTANDING</th>\n",
       "      <th>SEX</th>\n",
       "      <th>CUSTOMER_OPEN_DATE</th>\n",
       "      <th>BIRTH_DATE</th>\n",
       "      <th>PROFESSION</th>\n",
       "      <th>CAR_TYPE</th>\n",
       "      <th>BINARIZED_TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>893110</th>\n",
       "      <td>2019-08-29</td>\n",
       "      <td>Auto Loans 50% Down Payment - Employed</td>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>2024-09-03</td>\n",
       "      <td>288750.0</td>\n",
       "      <td>290097.50</td>\n",
       "      <td>M</td>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>1974-01-17</td>\n",
       "      <td>Company Owner</td>\n",
       "      <td>HYUNDAI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564178</th>\n",
       "      <td>2018-02-28</td>\n",
       "      <td>Auto Loans 50% Down Payment - Self Employed</td>\n",
       "      <td>2015-02-09</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>F</td>\n",
       "      <td>2010-08-09</td>\n",
       "      <td>1971-01-03</td>\n",
       "      <td>HOUSEWIFE</td>\n",
       "      <td>Saipa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888003</th>\n",
       "      <td>2019-08-29</td>\n",
       "      <td>Auto Loans 40% Down Payment - Employed</td>\n",
       "      <td>2016-09-26</td>\n",
       "      <td>2023-09-03</td>\n",
       "      <td>70200.0</td>\n",
       "      <td>50953.96</td>\n",
       "      <td>M</td>\n",
       "      <td>2016-09-06</td>\n",
       "      <td>1974-01-26</td>\n",
       "      <td>Manager</td>\n",
       "      <td>HYUNDAI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257509</th>\n",
       "      <td>2016-11-30</td>\n",
       "      <td>Auto Loans 30% Down Payment - Self Employed</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>2023-05-03</td>\n",
       "      <td>129500.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>M</td>\n",
       "      <td>2016-04-19</td>\n",
       "      <td>1988-03-10</td>\n",
       "      <td>Company Owner</td>\n",
       "      <td>HYUNDAI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896560</th>\n",
       "      <td>2019-08-29</td>\n",
       "      <td>Auto Loans 30% Down Payment - Employed</td>\n",
       "      <td>2015-06-11</td>\n",
       "      <td>2020-08-03</td>\n",
       "      <td>72730.0</td>\n",
       "      <td>22819.58</td>\n",
       "      <td>F</td>\n",
       "      <td>2015-03-05</td>\n",
       "      <td>1978-10-04</td>\n",
       "      <td>Manager</td>\n",
       "      <td>SUZUKI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       REPORTING_DATE                                 PROGRAM_NAME  \\\n",
       "893110     2019-08-29       Auto Loans 50% Down Payment - Employed   \n",
       "564178     2018-02-28  Auto Loans 50% Down Payment - Self Employed   \n",
       "888003     2019-08-29       Auto Loans 40% Down Payment - Employed   \n",
       "257509     2016-11-30  Auto Loans 30% Down Payment - Self Employed   \n",
       "896560     2019-08-29       Auto Loans 30% Down Payment - Employed   \n",
       "\n",
       "       LOAN_OPEN_DATE EXPECTED_CLOSE_DATE  ORIGINAL_BOOKED_AMOUNT  \\\n",
       "893110     2019-08-26          2024-09-03                288750.0   \n",
       "564178     2015-02-09          2020-02-03                 30000.0   \n",
       "888003     2016-09-26          2023-09-03                 70200.0   \n",
       "257509     2016-04-24          2023-05-03                129500.0   \n",
       "896560     2015-06-11          2020-08-03                 72730.0   \n",
       "\n",
       "        OUTSTANDING SEX CUSTOMER_OPEN_DATE BIRTH_DATE     PROFESSION CAR_TYPE  \\\n",
       "893110    290097.50   M         2019-07-30 1974-01-17  Company Owner  HYUNDAI   \n",
       "564178         0.00   F         2010-08-09 1971-01-03      HOUSEWIFE    Saipa   \n",
       "888003     50953.96   M         2016-09-06 1974-01-26        Manager  HYUNDAI   \n",
       "257509         0.00   M         2016-04-19 1988-03-10  Company Owner  HYUNDAI   \n",
       "896560     22819.58   F         2015-03-05 1978-10-04        Manager   SUZUKI   \n",
       "\n",
       "        BINARIZED_TARGET  \n",
       "893110                 0  \n",
       "564178                 0  \n",
       "888003                 0  \n",
       "257509                 0  \n",
       "896560                 1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dirty variable selection, feature transformation and data cleanning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specific_columns(df, data_types, to_ignore = list(), ignore_target = False):\n",
    "    columns = df.select_dtypes(include=data_types).columns\n",
    "    if ignore_target:\n",
    "        columns = filter(lambda x: x not in to_ignore, list(columns))\n",
    "    return list(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'BINARIZED_TARGET'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_numeric_variables = get_specific_columns(df, [\"float64\", \"int64\"], [target], ignore_target = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression - Full Model - all variables\n",
    "You sould use LogisticRegression in the modeling part to avoid any overfitting issues, and also split your data into train and test split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "splitter = train_test_split\n",
    "\"-----------------------\"\n",
    "\n",
    "df_train, df_test = splitter(df, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[all_numeric_variables]\n",
    "y_train = df_train[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test[all_numeric_variables]\n",
    "y_test = df_test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "method = LogisticRegression(random_state=0)\n",
    "fitted_full_model = method.fit(X_train, y_train)\n",
    "y_pred = fitted_full_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90625"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GINI vs Accuracy - use GINI for this analysis!\n",
    "\n",
    "GINI as well as accuracy is a 0 to 1 measure, 0 being very bad prediction and 1 being perfect separation.\n",
    "For this project __you should use GINI__ as it looks the model in all predictions (all range of probabilities), accuracy gets the probability and using a cut-off and transform the probability into predicted class 0 for probabilities below 50% and predicted class 1 for above or equal to 50%. So using accuracy makes our analysis for segmentation very short sighted as the result of the analysis could change if one changes the cut-off to let say 40%, for this reason we will use the GINI coeficient which is independent of the cut-off having a better overview of the whole model predictions.\n",
    "\n",
    "GINI is a simple calculation resulting from AUC. You will not find directly the Gini Coefficient as an attribute for the LogisticRegressor Class, but you can use the 2*AUC-1 formula to calculate it. \n",
    "\n",
    "If you want more details about GINI have a look into this video:\n",
    "https://www.youtube.com/watch?v=MiBUBVUC8kE\n",
    "\n",
    "\n",
    "Make sure you use .predict_proba (to predict probability) and then get the first column using [:,1] to get only the probability of being 1, instead of .predict which gives the 0 or 1 class. This proba is  what you need to pass as predictions_list below, to finally obtain the GINI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09977650063856958\n"
     ]
    }
   ],
   "source": [
    "y_pred_probadbility = fitted_full_model.predict_proba(X_test)[:,1]\n",
    "#y_test is your actual 0 and 1 class and y_pred_probadbility is the predicted probability of belonging to class 1.\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probadbility)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "GINI = (2 * roc_auc) - 1\n",
    "print(GINI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Model 1 - Gender M and F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    1379\n",
       "F     540\n",
       "Name: SEX, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SEX'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "df_train_seg1 = df_train[df['SEX'] == \"M\"]\n",
    "df_train_seg2 = df_train[df['SEX'] != \"M\"]\n",
    "df_test_seg1 = df_test[df['SEX'] == \"M\"]\n",
    "df_test_seg2 = df_test[df['SEX'] != \"M\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Model vs Seg 1 on Seg 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment1: SEX in ('M') [GINI Full Model: 0.0887% / GINI Segmented Model: 0.0887%]\n"
     ]
    }
   ],
   "source": [
    "X_train_seg1 = df_train_seg1[all_numeric_variables]\n",
    "y_train_seg1 = df_train_seg1[target]\n",
    "X_test_seg1 = df_test_seg1[all_numeric_variables]\n",
    "y_test_seg1 = df_test_seg1[target]\n",
    "fitted_model_seg1 = method.fit(X_train_seg1, y_train_seg1)\n",
    "\n",
    "def GINI(y_test, y_pred_probadbility):\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_probadbility)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    GINI = (2 * roc_auc) - 1\n",
    "    return(GINI)\n",
    "\n",
    "y_pred_seg1_proba = fitted_model_seg1.predict_proba(X_test_seg1)[:,1]\n",
    "y_pred_seg1_fullmodel_proba = fitted_full_model.predict_proba(X_test_seg1)[:,1]\n",
    "\n",
    "print(\"Segment1: SEX in ('M') [GINI Full Model: {:.4f}% / GINI Segmented Model: {:.4f}%]\".format(\n",
    "    GINI(y_test_seg1, y_pred_seg1_proba)*100,\n",
    "    GINI(y_test_seg1, y_pred_seg1_fullmodel_proba)*100\n",
    ")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Model vs Seg 2 on Seg 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment1: SEX in ('F') [GINI Full Model: 57.8431% / GINI Segmented Model: 57.8431%]\n"
     ]
    }
   ],
   "source": [
    "X_train_seg2 = df_train_seg2[all_numeric_variables]\n",
    "y_train_seg2 = df_train_seg2[target]\n",
    "X_test_seg2 = df_test_seg2[all_numeric_variables]\n",
    "y_test_seg2 = df_test_seg2[target]\n",
    "fitted_model_seg2 = method.fit(X_train_seg2, y_train_seg2)\n",
    "\n",
    "y_pred_seg2_proba = fitted_model_seg2.predict_proba(X_test_seg2)[:,1]\n",
    "y_pred_seg2_fullmodel_proba = fitted_full_model.predict_proba(X_test_seg2)[:,1]\n",
    "\n",
    "print(\"Segment1: SEX in ('F') [GINI Full Model: {:.4f}% / GINI Segmented Model: {:.4f}%]\".format(\n",
    "    GINI(y_test_seg2, y_pred_seg2_proba)*100,\n",
    "    GINI(y_test_seg2, y_pred_seg2_fullmodel_proba)*100\n",
    "))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution Summary Repport\n",
    "\n",
    "&emsp;\n",
    "BUCKET is the target variable and was not analyzed separetly.\n",
    "\n",
    "__Missing Not At Random Repport__ -  REPORTING_DATE, ACCOUNT_NUMBER, CUSTOMER_ID variables seem Missing Not at Random, there for we recommend:\n",
    "\n",
    "&emsp;  Thin File Segment Variables: PROGRAM_NAME, LOAN_OPEN_DATE, EXPECTED_CLOSE_DATE, \n",
    "ORIGINAL_BOOKED_AMOUNT, OUTSTANDING, SEX, \n",
    "CUSTOMER_OPEN_DATE, BIRTH_DATE, PROFESSION, CAR_TYPE\n",
    "\n",
    "&emsp; Full File Segment Variables: REPORTING_DATE, ACCOUNT_NUMBER, CUSTOMER_ID, PROGRAM_NAME, LOAN_OPEN_DATE, EXPECTED_CLOSE_DATE, ORIGINAL_BOOKED_AMOUNT, \n",
    "OUTSTANDING, SEX, CUSTOMER_OPEN_DATE, BIRTH_DATE, PROFESSION, CAR_TYPE\n",
    "\n",
    "__Variable by Variable Risk Based Segmentation Analysis__:\n",
    "\n",
    "&emsp; REPORTING_DATE Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; ACCOUNT_NUMBER Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; CUSTOMER_ID Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; PROGRAM_NAME Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; LOAN_OPEN_DATE Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; EXPECTED_CLOSE_DATE Good for segmentation.  \n",
    "\n",
    "&emsp; &emsp; Segment1: EXPECTED_CLOSE_DATE < '22/07/2021'  [GINI Full Model: 32.1234% / GINI Segmented Model: 33.4342%]\n",
    "\n",
    "&emsp; &emsp;  Segment2: EXPECTED_CLOSE_DATE >= '22/07/2021' [GINI Full Model: 63.7523% / GINI Segmented Model: 68.8342%]\n",
    "\n",
    "&emsp; ORIGINAL_BOOKED_AMOUNT Good for segmentation.  \n",
    "\n",
    "&emsp; &emsp; Segment1: ORIGINAL_BOOKED_AMOUNT < 90000 [GINI Full Model: 32.3243% / GINI Segmented Model: 33.9833%]\n",
    "\n",
    "&emsp; &emsp; Segment2: ORIGINAL_BOOKED_AMOUNT >= 90000 [GINI Full Model: 63.3449% / GINI Segmented Model: 68.9438%]\n",
    "\n",
    "&emsp; OUTSTANDING Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; SEX Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; CUSTOMER_OPEN_DATE Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; CUSTOMER_OPEN_DATE Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; BIRTH_DATE Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; PROFESSION Not good for segmentation. Afer analysis, we did not find a good split using this variable.\n",
    "\n",
    "&emsp; CAR_TYPE Good for segmentation.  \n",
    "\n",
    "&emsp; &emsp; Segment1: CAR_TYPE in (BMW', 'BYD', 'CARRY', 'Changan', 'CHEVROLET', 'Gelory', 'GELY', 'HYUNDAI') [GINI Full Model: 35.3492% / GINI Segmented Model: 37.3943%]\n",
    "\n",
    "&emsp; &emsp; Segment2: CAR_TYPE in ('Jack', 'KIA', 'MERCEDES', 'MITSUBISHI', 'NISSAN', 'RENAULT', 'SEAT', 'SKODA', 'SUZUKI') [GINI Full Model: 42.4324% / GINI Segmented Model: 49.4393%]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
