{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Individual Project\n",
    "\n",
    "<img src=\"fer.png\" width=100 height=100 align=\"right\">\n",
    "\n",
    "Author: Fernando GodÃ­nez Cornejo\n",
    "\n",
    "Contact: fernando.godinez@student.ie.edu\n",
    "\n",
    "Web: linkedin.com/fernandogodinezc\n",
    "\n",
    "Last revision: 22/Aug/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download libraries to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+http://github.com/renero/dataset\n",
      "  Cloning http://github.com/renero/dataset to /private/var/folders/wv/yvq0c5md1zj9wnt_vwjs6vpc0000gn/T/pip-req-build-2t4jrf99\n",
      "Requirement already satisfied, skipping upgrade: matplotlib in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from dataset==0.17.1) (3.3.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from dataset==0.17.1) (1.19.2)\n",
      "Requirement already satisfied, skipping upgrade: pandas in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from dataset==0.17.1) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit_learn in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from dataset==0.17.1) (0.23.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from dataset==0.17.1) (1.5.2)\n",
      "Requirement already satisfied, skipping upgrade: seaborn in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from dataset==0.17.1) (0.11.0)\n",
      "Requirement already satisfied, skipping upgrade: sklearn_pandas in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from dataset==0.17.1) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: skrebate in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from dataset==0.17.1) (0.62)\n",
      "Requirement already satisfied, skipping upgrade: statsmodels in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from dataset==0.17.1) (0.12.0)\n",
      "Requirement already satisfied, skipping upgrade: nbsphinx in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from dataset==0.17.1) (0.8.6)\n",
      "Requirement already satisfied, skipping upgrade: pillow>=6.2.0 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->dataset==0.17.1) (8.0.1)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2020.06.20 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->dataset==0.17.1) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->dataset==0.17.1) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->dataset==0.17.1) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->dataset==0.17.1) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->dataset==0.17.1) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.3 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from pandas->dataset==0.17.1) (2020.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from scikit_learn->dataset==0.17.1) (0.17.0)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from scikit_learn->dataset==0.17.1) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: patsy>=0.5 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from statsmodels->dataset==0.17.1) (0.5.1)\n",
      "Requirement already satisfied, skipping upgrade: nbformat in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbsphinx->dataset==0.17.1) (5.0.8)\n",
      "Requirement already satisfied, skipping upgrade: docutils in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbsphinx->dataset==0.17.1) (0.16)\n",
      "Requirement already satisfied, skipping upgrade: traitlets in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbsphinx->dataset==0.17.1) (5.0.5)\n",
      "Requirement already satisfied, skipping upgrade: sphinx>=1.8 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbsphinx->dataset==0.17.1) (3.2.1)\n",
      "Requirement already satisfied, skipping upgrade: jinja2 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbsphinx->dataset==0.17.1) (2.11.2)\n",
      "Requirement already satisfied, skipping upgrade: nbconvert!=5.4 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbsphinx->dataset==0.17.1) (6.0.7)\n",
      "Requirement already satisfied, skipping upgrade: six in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->dataset==0.17.1) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: ipython-genutils in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbformat->nbsphinx->dataset==0.17.1) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-core in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbformat->nbsphinx->dataset==0.17.1) (4.6.3)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema!=2.5.0,>=2.4 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbformat->nbsphinx->dataset==0.17.1) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: sphinxcontrib-htmlhelp in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from sphinx>=1.8->nbsphinx->dataset==0.17.1) (1.0.3)\n",
      "Requirement already satisfied, skipping upgrade: sphinxcontrib-jsmath in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from sphinx>=1.8->nbsphinx->dataset==0.17.1) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from sphinx>=1.8->nbsphinx->dataset==0.17.1) (20.4)\n",
      "Requirement already satisfied, skipping upgrade: sphinxcontrib-applehelp in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from sphinx>=1.8->nbsphinx->dataset==0.17.1) (1.0.2)\n",
      "Requirement already satisfied, skipping upgrade: Pygments>=2.0 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from sphinx>=1.8->nbsphinx->dataset==0.17.1) (2.7.2)\n",
      "Requirement already satisfied, skipping upgrade: snowballstemmer>=1.1 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from sphinx>=1.8->nbsphinx->dataset==0.17.1) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: sphinxcontrib-serializinghtml in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from sphinx>=1.8->nbsphinx->dataset==0.17.1) (1.1.4)\n",
      "Requirement already satisfied, skipping upgrade: sphinxcontrib-devhelp in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from sphinx>=1.8->nbsphinx->dataset==0.17.1) (1.0.2)\n",
      "Requirement already satisfied, skipping upgrade: sphinxcontrib-qthelp in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from sphinx>=1.8->nbsphinx->dataset==0.17.1) (1.0.3)\n",
      "Requirement already satisfied, skipping upgrade: babel>=1.3 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from sphinx>=1.8->nbsphinx->dataset==0.17.1) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: alabaster<0.8,>=0.7 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from sphinx>=1.8->nbsphinx->dataset==0.17.1) (0.7.12)\n",
      "Requirement already satisfied, skipping upgrade: imagesize in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from sphinx>=1.8->nbsphinx->dataset==0.17.1) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: requests>=2.5.0 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from sphinx>=1.8->nbsphinx->dataset==0.17.1) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from sphinx>=1.8->nbsphinx->dataset==0.17.1) (50.3.1.post20201107)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from jinja2->nbsphinx->dataset==0.17.1) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: jupyterlab-pygments in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbconvert!=5.4->nbsphinx->dataset==0.17.1) (0.1.2)\n",
      "Requirement already satisfied, skipping upgrade: nbclient<0.6.0,>=0.5.0 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbconvert!=5.4->nbsphinx->dataset==0.17.1) (0.5.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied, skipping upgrade: mistune<2,>=0.8.1 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbconvert!=5.4->nbsphinx->dataset==0.17.1) (0.8.4)\n",
      "Requirement already satisfied, skipping upgrade: pandocfilters>=1.4.1 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbconvert!=5.4->nbsphinx->dataset==0.17.1) (1.4.3)\n",
      "Requirement already satisfied, skipping upgrade: bleach in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbconvert!=5.4->nbsphinx->dataset==0.17.1) (3.2.1)\n",
      "Requirement already satisfied, skipping upgrade: entrypoints>=0.2.2 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbconvert!=5.4->nbsphinx->dataset==0.17.1) (0.3)\n",
      "Requirement already satisfied, skipping upgrade: testpath in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbconvert!=5.4->nbsphinx->dataset==0.17.1) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: defusedxml in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbconvert!=5.4->nbsphinx->dataset==0.17.1) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->nbsphinx->dataset==0.17.1) (20.3.0)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->nbsphinx->dataset==0.17.1) (0.17.3)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.5.0->sphinx>=1.8->nbsphinx->dataset==0.17.1) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.5.0->sphinx>=1.8->nbsphinx->dataset==0.17.1) (1.25.11)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.5.0->sphinx>=1.8->nbsphinx->dataset==0.17.1) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-client>=6.1.5 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert!=5.4->nbsphinx->dataset==0.17.1) (6.1.7)\n",
      "Requirement already satisfied, skipping upgrade: async-generator in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert!=5.4->nbsphinx->dataset==0.17.1) (1.10)\n",
      "Requirement already satisfied, skipping upgrade: nest-asyncio in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert!=5.4->nbsphinx->dataset==0.17.1) (1.4.2)\n",
      "Requirement already satisfied, skipping upgrade: webencodings in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from bleach->nbconvert!=5.4->nbsphinx->dataset==0.17.1) (0.5.1)\n",
      "Requirement already satisfied, skipping upgrade: tornado>=4.1 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert!=5.4->nbsphinx->dataset==0.17.1) (6.0.4)\n",
      "Requirement already satisfied, skipping upgrade: pyzmq>=13 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert!=5.4->nbsphinx->dataset==0.17.1) (19.0.2)\n",
      "Building wheels for collected packages: dataset\n",
      "  Building wheel for dataset (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dataset: filename=dataset-0.17.1-py3-none-any.whl size=22736 sha256=929a315dc6fd8596c7b411fbf27a2b208eed875558a21dbe414c1588d1b39e35\n",
      "  Stored in directory: /private/var/folders/wv/yvq0c5md1zj9wnt_vwjs6vpc0000gn/T/pip-ephem-wheel-cache-ruoyxddp/wheels/5e/d1/b3/9ef477d13c9620bcfd5984012b4831ba1a2641562d7b0e6b78\n",
      "Successfully built dataset\n",
      "Installing collected packages: dataset\n",
      "  Attempting uninstall: dataset\n",
      "    Found existing installation: dataset 0.17.1\n",
      "    Uninstalling dataset-0.17.1:\n",
      "      Successfully uninstalled dataset-0.17.1\n",
      "Successfully installed dataset-0.17.1\n",
      "Requirement already satisfied: skrebate in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (0.62)\n",
      "Requirement already satisfied: numpy in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from skrebate) (1.19.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from skrebate) (0.23.2)\n",
      "Requirement already satisfied: scipy in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from skrebate) (1.5.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->skrebate) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->skrebate) (2.1.0)\n",
      "Requirement already satisfied: gplearn in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (0.4.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from gplearn) (0.23.2)\n",
      "Requirement already satisfied: joblib>=0.13.0 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from gplearn) (0.17.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.20.0->gplearn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.20.0->gplearn) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.20.0->gplearn) (1.19.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade git+http://github.com/renero/dataset\n",
    "!pip install skrebate\n",
    "!pip install gplearn\n",
    "\n",
    "from copy import copy\n",
    "from dataset import Dataset\n",
    "from datetime import datetime, date\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import re\n",
    "import math\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class creation\n",
    "\n",
    "Hi Professor!\n",
    "\n",
    "My idea is to develop a flow for the end user to handle any type of document by just providing the inputs (columns).\n",
    "\n",
    "The class has four main sections:\n",
    "1. Initialization: to upload the dataframe from any csv\n",
    "2. Cleaning: Composed by six different functions (private) and ordered in a logic flow. \n",
    "3. Categorical Analysis \n",
    "4. Numerical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiskEvaluation():\n",
    "\n",
    "    # Class initialization by giving the dataFrame\n",
    "    def  __init__(self,filename) :\n",
    "        self.data = pd.read_csv(filename)\n",
    "        \n",
    "    # Cleaning of data\n",
    "    def inicial (self,piv,birth_date,target,down_payment,income_status,dates_todays) :\n",
    "        self._pivot_unique(piv)\n",
    "        self._clean_target(target)\n",
    "        self._clean(birth_date)\n",
    "        self._down(down_payment)\n",
    "        self._income(income_status)\n",
    "        self._dayslapsed(dates_todays)\n",
    "        return self.data\n",
    "    \n",
    "    #Remove duplicates using the 'pivot' value established by the user\n",
    "    def _pivot_unique (self,piv) :\n",
    "        self.data.drop_duplicates(subset=[piv], keep='last', inplace = True)\n",
    "        return self.data\n",
    "    \n",
    "    #The idea of this analysis is to have a binary bucket \n",
    "    def _clean_target (self,target) :\n",
    "        for i in range(len(self.data.columns)):\n",
    "            tar = str(self.data.columns[i])\n",
    "            if tar == target :\n",
    "                val = np.where(self.data[self.data.columns[i]]>0,1,self.data[self.data.columns[i]])\n",
    "                self.data[self.data.columns[i]] = val\n",
    "        return self.data\n",
    "    \n",
    "    # Getting the agre from the birth date in the dataFrame and cleainig empty spaces\n",
    "    def _clean(self,birth_date) :\n",
    "\n",
    "        data = Dataset.from_dataframe(self.data)\n",
    "        numerical_features = data.numerical_features\n",
    "        categorical_features = data.categorical_features\n",
    "        \n",
    "        # clean numerical values\n",
    "        for i in range(len(self.data.columns)):\n",
    "            empty = self.data[self.data.columns[i]].isna().any()\n",
    "            if empty == True and self.data.columns[i] in numerical_features:\n",
    "                val = self.data[self.data.columns[i]].fillna(self.data[self.data.columns[i]].mean())\n",
    "                self.data[self.data.columns[i]] = val\n",
    "        \n",
    "        # clean categorical values\n",
    "            # fill empty\n",
    "        for i in range(len(self.data.columns)):\n",
    "            empty = self.data[self.data.columns[i]].isna().any()\n",
    "            if empty == True and self.data.columns[i] in categorical_features:\n",
    "                val = self.data[self.data.columns[i]].fillna('UNKNOWN')\n",
    "                self.data[self.data.columns[i]] = val\n",
    "            \n",
    "            # upper case\n",
    "        for i in range(len(self.data.columns)):\n",
    "            if self.data.columns[i] in categorical_features:\n",
    "                val = self.data[self.data.columns[i]].str.upper()\n",
    "                self.data[self.data.columns[i]] = val\n",
    "        \n",
    "        # if birth date, return age\n",
    "        def age(born):\n",
    "            while True:\n",
    "                try:\n",
    "                    born = datetime.datetime.strptime(born, \"%Y-%m-%d\").date()\n",
    "                    today = date.today()\n",
    "                    return today.year - born.year - ((today.month, today.day) < (born.month, born.day))\n",
    "                except ValueError:\n",
    "                    return 'UNKNOWN'\n",
    "        for i in range(len(self.data.columns)):\n",
    "            dateb = str(self.data.columns[i])\n",
    "            if self.data.columns[i] in categorical_features and dateb == birth_date :\n",
    "                val = self.data[self.data.columns[i]].apply(age)\n",
    "                self.data[self.data.columns[i]] = val\n",
    "\n",
    "        return self.data\n",
    "\n",
    "    # The down Payment has to mean something in order to be useful in the Model. We get the % in each value. Also we separate between individuals and corporate\n",
    "    \n",
    "    def _down(self,down_payment) :\n",
    "        def pay(payment) :\n",
    "            y = re.findall('\\d+', payment)\n",
    "            if len(y) > 0 :\n",
    "                result = int(y[0])/100\n",
    "            else:\n",
    "                result = 0\n",
    "            return result\n",
    "        \n",
    "        def ty(types) :\n",
    "            if 'EMPLOYED' in types :\n",
    "                return 'EMPLOYED'\n",
    "            else:\n",
    "                return 'CORPORATE'\n",
    "        \n",
    "        self.data[\"DOWN_PAYMENT\"] = None\n",
    "        self.data[\"TYPE\"] = None\n",
    "        val = self.data[down_payment].apply(pay)\n",
    "        self.data[\"DOWN_PAYMENT\"] = val\n",
    "        \n",
    "        val = self.data[down_payment].apply(ty)\n",
    "        self.data[\"TYPE\"] = val\n",
    "        self.data.drop(columns = [down_payment], inplace = True)\n",
    "        \n",
    "        return self.data\n",
    "    \n",
    "    # There are too many jobs, we can isolate between those who get some income and unemployed guys\n",
    "    def _income (self,income_status) :\n",
    "        def income(incomes) :\n",
    "            if 'UNEMPLOYED' in incomes :\n",
    "                return 'UNEMPLOYED'\n",
    "            else:\n",
    "                return 'ACTIVE' \n",
    "       \n",
    "        val = self.data[income_status].apply(income)\n",
    "        self.data[income_status] = val\n",
    "    \n",
    "    # Dates are not useful for the model, we need numerical values.\n",
    "    \n",
    "    def _dayslapsed (self,dates_todays):\n",
    "        def daily(dai) :\n",
    "            change = datetime.datetime.strptime(dai, \"%Y-%m-%d\").date()\n",
    "            today = date.today()\n",
    "            delta = today - change\n",
    "            return delta.days\n",
    "        \n",
    "        for i in range(len(dates_todays)):\n",
    "            self.data[dates_todays[i]+'_DAYS_LAPSED'] = None\n",
    "            val = self.data[dates_todays[i]].apply(daily)\n",
    "            self.data[dates_todays[i]+'_DAYS_LAPSED'] = val\n",
    "            self.data.drop(columns = [dates_todays[i]], inplace = True)\n",
    "    \n",
    "    \n",
    "    # Lets use categorical values established by the user\n",
    "    \n",
    "    def set_train_cat (self,target_value,seg_data):\n",
    "        \n",
    "        df_random_sample, _ = train_test_split(self.data, test_size=0.80)\n",
    "        \n",
    "        \n",
    "        def get_specific_columns(df_random_sample, data_types, to_ignore = list(), ignore_target = False):\n",
    "            columns = df_random_sample.select_dtypes(include=data_types).columns\n",
    "            if ignore_target:\n",
    "                columns = filter(lambda x: x not in to_ignore, list(columns))\n",
    "            return list(columns)\n",
    "        \n",
    "        all_numeric_variables = get_specific_columns(df_random_sample, [\"float64\", \"int64\"], [target_value], ignore_target = True)\n",
    "        \n",
    "        splitter = train_test_split\n",
    "        df_train, df_test = splitter(df_random_sample, test_size = 0.2, random_state = 42)\n",
    "        \n",
    "        X_train = df_train[all_numeric_variables]\n",
    "        y_train = df_train[target_value]\n",
    "        \n",
    "        X_test = df_test[all_numeric_variables]\n",
    "        y_test = df_test[target_value]\n",
    "        \n",
    "        method = LogisticRegression(random_state=0)\n",
    "        fitted_full_model = method.fit(X_train, y_train)\n",
    "        y_pred = fitted_full_model.predict(X_test)\n",
    "        \n",
    "        # Result accuracy all model\n",
    "        full_model = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        result_full_model_etal =  [\"The total accuracy using all variable is: \" + str(full_model)]\n",
    "        \n",
    "        #Analysis Model\n",
    "        for seg in range(len(seg_data)):\n",
    "            max_value_seg = self.data[seg_data[seg]].value_counts().idxmax()\n",
    "            \n",
    "            # set dataframes of train and test\n",
    "            \n",
    "            df_train_seg1 = df_train[df_random_sample[seg_data[seg]] == max_value_seg]\n",
    "            df_train_seg2 = df_train[df_random_sample[seg_data[seg]] != max_value_seg]\n",
    "            df_test_seg1 = df_test[df_random_sample[seg_data[seg]] == max_value_seg]\n",
    "            df_test_seg2 = df_test[df_random_sample[seg_data[seg]] != max_value_seg]\n",
    "            \n",
    "            #getting results seg 1 vs seg 1\n",
    "           \n",
    "            X_train_seg1 = df_train_seg1[all_numeric_variables]\n",
    "            y_train_seg1 = df_train_seg1[target_value]\n",
    "            X_test_seg1 = df_test_seg1[all_numeric_variables]\n",
    "            y_test_seg1 = df_test_seg1[target_value]\n",
    "            fitted_model_seg1 = method.fit(X_train_seg1, y_train_seg1)\n",
    "            y_pred_seg1 = fitted_model_seg1.predict(X_test_seg1)\n",
    "            y_pred_seg1_fullmodel = fitted_full_model.predict(X_test_seg1)\n",
    "            \n",
    "            result_full_model_etal.append(\"Using: \" + seg_data[seg] + \" Model Developed on Seg 1 (train sample) applied on Seg 1 (test sample):\"+str(accuracy_score(y_test_seg1, y_pred_seg1)))\n",
    "            result_full_model_etal.append(\"Using: \" + seg_data[seg] + \" Model Developed on Full Population (train sample) applied on Seg 1 (test sample):\"+str(accuracy_score(y_test_seg1, y_pred_seg1_fullmodel)))\n",
    "            \n",
    "            #getting results seg 2 vs seg 2\n",
    "            \n",
    "            X_train_seg2 = df_train_seg2[all_numeric_variables]\n",
    "            y_train_seg2 = df_train_seg2[target_value]\n",
    "            X_test_seg2 = df_test_seg2[all_numeric_variables]\n",
    "            y_test_seg2 = df_test_seg2[target_value]\n",
    "            fitted_model_seg2 = method.fit(X_train_seg2, y_train_seg2)\n",
    "            y_pred_seg2 = fitted_model_seg2.predict(X_test_seg2)\n",
    "            y_pred_seg2_fullmodel = fitted_full_model.predict(X_test_seg2)\n",
    "            result_full_model_etal.append(\"Using: \" + seg_data[seg] +\" Model Developed on Full Population (train sample) applied on Seg 2 (test sample):\" + str(accuracy_score(y_test_seg2, y_pred_seg2_fullmodel)))\n",
    "            result_full_model_etal.append(\"Using: \" + seg_data[seg] +\" Model Developed on Seg 2 (train sample) applied on Seg 2 (test sample):\" + str(accuracy_score(y_test_seg2, y_pred_seg2))) \n",
    "        \n",
    "        return result_full_model_etal\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Now numercial columns\n",
    "    \n",
    "    def set_train_num (self,seg_data_cat,target_value,seg_data_num): \n",
    "        \n",
    "        #One hot encoding\n",
    "        data = Dataset.from_dataframe(self.data)\n",
    "        \n",
    "        for seg in range(len(seg_data_cat)):\n",
    "            data.onehot_encode(seg_data_cat[seg])\n",
    "            data.drop_columns(seg_data_cat[seg])\n",
    "        \n",
    "        self.data = data.features\n",
    "        \n",
    "        # Lets get rid of Unknown values so that we can have means in each column\n",
    "        for dro in range(len(seg_data_num)):\n",
    "            self.data.drop(self.data.index[self.data[seg_data_num[dro]] == 'UNKNOWN'], inplace = True)\n",
    "        \n",
    "        def get_specific_columns(df_random_sample, data_types, to_ignore = list(), ignore_target = False):\n",
    "            columns = df_random_sample.select_dtypes(include=data_types).columns\n",
    "            if ignore_target:\n",
    "                columns = filter(lambda x: x not in to_ignore, list(columns))\n",
    "            return list(columns)\n",
    "        \n",
    "        #select data\n",
    "        df_random_sample, _ = train_test_split(self.data, test_size=0.80)\n",
    "        all_numeric_variables = get_specific_columns(df_random_sample, [\"float64\", \"int64\"], [target_value], ignore_target = True)\n",
    "        \n",
    "        splitter = train_test_split\n",
    "        df_train, df_test = splitter(df_random_sample, test_size = 0.2, random_state = 42)\n",
    "        \n",
    "        result_full_model_etal = []\n",
    "        \n",
    "        X_train = df_train[all_numeric_variables]\n",
    "        y_train = df_train[target_value]\n",
    "        \n",
    "        X_test = df_test[all_numeric_variables]\n",
    "        y_test = df_test[target_value]\n",
    "        \n",
    "        method = LogisticRegression(random_state=0)\n",
    "        fitted_full_model = method.fit(X_train, y_train)\n",
    "        y_pred = fitted_full_model.predict(X_test)\n",
    "        \n",
    "        full_model = accuracy_score(y_test, y_pred)\n",
    "        result_full_model_etal =  [\"The total accuracy using all variable is: \" + str(full_model)]\n",
    "        \n",
    "        #Analysis Model\n",
    "        for seg in range(len(seg_data_num)):\n",
    "            \n",
    "            mean_value_seg = self.data[seg_data_num[seg]].mean()\n",
    "            \n",
    "            # set dataframes of train and test\n",
    "            \n",
    "            df_train_seg1 = df_train[df_random_sample[seg_data_num[seg]] >= mean_value_seg]\n",
    "            df_train_seg2 = df_train[df_random_sample[seg_data_num[seg]] < mean_value_seg]\n",
    "            df_test_seg1 = df_test[df_random_sample[seg_data_num[seg]] >=  mean_value_seg]\n",
    "            df_test_seg2 = df_test[df_random_sample[seg_data_num[seg]] < mean_value_seg]\n",
    "            \n",
    "            #getting results seg 1 vs seg 1\n",
    "           \n",
    "            X_train_seg1 = df_train_seg1[all_numeric_variables]\n",
    "            y_train_seg1 = df_train_seg1[target_value]\n",
    "            X_test_seg1 = df_test_seg1[all_numeric_variables]\n",
    "            y_test_seg1 = df_test_seg1[target_value]\n",
    "            fitted_model_seg1 = method.fit(X_train_seg1, y_train_seg1)\n",
    "            y_pred_seg1 = fitted_model_seg1.predict(X_test_seg1)\n",
    "            y_pred_seg1_fullmodel = fitted_full_model.predict(X_test_seg1)\n",
    "            \n",
    "            result_full_model_etal.append(\"Using: \" + seg_data_num[seg] + \" Model Developed on Seg 1 (train sample) applied on Seg 1 (test sample):\"+str(accuracy_score(y_test_seg1, y_pred_seg1)))\n",
    "            result_full_model_etal.append(\"Using: \" + seg_data_num[seg] + \" Model Developed on Full Population (train sample) applied on Seg 1 (test sample):\"+str(accuracy_score(y_test_seg1, y_pred_seg1_fullmodel)))\n",
    "            \n",
    "            #getting results seg 2 vs seg 2\n",
    "            \n",
    "            X_train_seg2 = df_train_seg2[all_numeric_variables]\n",
    "            y_train_seg2 = df_train_seg2[target_value]\n",
    "            X_test_seg2 = df_test_seg2[all_numeric_variables]\n",
    "            y_test_seg2 = df_test_seg2[target_value]\n",
    "            fitted_model_seg2 = method.fit(X_train_seg2, y_train_seg2)\n",
    "            y_pred_seg2 = fitted_model_seg2.predict(X_test_seg2)\n",
    "            y_pred_seg2_fullmodel = fitted_full_model.predict(X_test_seg2)\n",
    "            result_full_model_etal.append(\"Using: \" + seg_data_num[seg] +\" Model Developed on Full Population (train sample) applied on Seg 2 (test sample):\" + str(accuracy_score(y_test_seg2, y_pred_seg2_fullmodel)))\n",
    "            result_full_model_etal.append(\"Using: \" + seg_data_num[seg] +\" Model Developed on Seg 2 (train sample) applied on Seg 2 (test sample):\" + str(accuracy_score(y_test_seg2, y_pred_seg2))) \n",
    "        \n",
    "        return result_full_model_etal\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start \n",
    "\n",
    "The user is going to feed the class with the selected file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = RiskEvaluation('AUTO_LOANS_DATA.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic variables and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACCOUNT_NUMBER</th>\n",
       "      <th>CUSTOMER_ID</th>\n",
       "      <th>ORIGINAL_BOOKED_AMOUNT</th>\n",
       "      <th>OUTSTANDING</th>\n",
       "      <th>BUCKET</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BIRTH_DATE</th>\n",
       "      <th>PROFESSION</th>\n",
       "      <th>CAR_TYPE</th>\n",
       "      <th>DOWN_PAYMENT</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>REPORTING_DATE_DAYS_LAPSED</th>\n",
       "      <th>LOAN_OPEN_DATE_DAYS_LAPSED</th>\n",
       "      <th>EXPECTED_CLOSE_DATE_DAYS_LAPSED</th>\n",
       "      <th>CUSTOMER_OPEN_DATE_DAYS_LAPSED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>140500.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>EMPLOYED</td>\n",
       "      <td>2030</td>\n",
       "      <td>2258</td>\n",
       "      <td>1541</td>\n",
       "      <td>3022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>36</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>EMPLOYED</td>\n",
       "      <td>2030</td>\n",
       "      <td>3554</td>\n",
       "      <td>1723</td>\n",
       "      <td>3567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>309</td>\n",
       "      <td>307</td>\n",
       "      <td>65500.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>44</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>EMPLOYED</td>\n",
       "      <td>2030</td>\n",
       "      <td>3260</td>\n",
       "      <td>1449</td>\n",
       "      <td>3266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>351</td>\n",
       "      <td>349</td>\n",
       "      <td>44500.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>40</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>EMPLOYED</td>\n",
       "      <td>2030</td>\n",
       "      <td>2603</td>\n",
       "      <td>1146</td>\n",
       "      <td>2608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>466</td>\n",
       "      <td>12</td>\n",
       "      <td>93000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CORPORATE</td>\n",
       "      <td>2030</td>\n",
       "      <td>3464</td>\n",
       "      <td>2033</td>\n",
       "      <td>7597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900855</th>\n",
       "      <td>36547</td>\n",
       "      <td>35528</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>78956.52</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>27</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>GELORY</td>\n",
       "      <td>0.5</td>\n",
       "      <td>EMPLOYED</td>\n",
       "      <td>724</td>\n",
       "      <td>1060</td>\n",
       "      <td>-742</td>\n",
       "      <td>1071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900856</th>\n",
       "      <td>39597</td>\n",
       "      <td>38396</td>\n",
       "      <td>92500.0</td>\n",
       "      <td>92826.06</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>43</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>GELORY</td>\n",
       "      <td>0.5</td>\n",
       "      <td>EMPLOYED</td>\n",
       "      <td>724</td>\n",
       "      <td>725</td>\n",
       "      <td>-1108</td>\n",
       "      <td>738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900857</th>\n",
       "      <td>38016</td>\n",
       "      <td>36905</td>\n",
       "      <td>140250.0</td>\n",
       "      <td>114919.47</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>41</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>NISSAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CORPORATE</td>\n",
       "      <td>724</td>\n",
       "      <td>885</td>\n",
       "      <td>172</td>\n",
       "      <td>936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900858</th>\n",
       "      <td>38899</td>\n",
       "      <td>37739</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>101714.25</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>DFSK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CORPORATE</td>\n",
       "      <td>724</td>\n",
       "      <td>788</td>\n",
       "      <td>-1016</td>\n",
       "      <td>817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900859</th>\n",
       "      <td>4350</td>\n",
       "      <td>4307</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>KIA</td>\n",
       "      <td>0.4</td>\n",
       "      <td>EMPLOYED</td>\n",
       "      <td>724</td>\n",
       "      <td>2541</td>\n",
       "      <td>719</td>\n",
       "      <td>2903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39597 rows Ã 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACCOUNT_NUMBER  CUSTOMER_ID  ORIGINAL_BOOKED_AMOUNT  OUTSTANDING  \\\n",
       "143                144          144                140500.0         0.00   \n",
       "247                248          248                 70000.0         0.00   \n",
       "308                309          307                 65500.0         0.00   \n",
       "350                351          349                 44500.0         0.00   \n",
       "465                466           12                 93000.0         0.00   \n",
       "...                ...          ...                     ...          ...   \n",
       "900855           36547        35528                 90000.0     78956.52   \n",
       "900856           39597        38396                 92500.0     92826.06   \n",
       "900857           38016        36905                140250.0    114919.47   \n",
       "900858           38899        37739                105000.0    101714.25   \n",
       "900859            4350         4307                120000.0         0.00   \n",
       "\n",
       "        BUCKET      SEX BIRTH_DATE PROFESSION CAR_TYPE  DOWN_PAYMENT  \\\n",
       "143          0        M         39     ACTIVE  UNKNOWN           0.5   \n",
       "247          1        F         36     ACTIVE  UNKNOWN           0.5   \n",
       "308          0        M         44     ACTIVE  UNKNOWN           0.5   \n",
       "350          1        M         40     ACTIVE  UNKNOWN           0.5   \n",
       "465          0  UNKNOWN    UNKNOWN     ACTIVE  UNKNOWN           0.0   \n",
       "...        ...      ...        ...        ...      ...           ...   \n",
       "900855       0        M         27     ACTIVE   GELORY           0.5   \n",
       "900856       0        F         43     ACTIVE   GELORY           0.5   \n",
       "900857       0        M         41     ACTIVE   NISSAN           0.0   \n",
       "900858       0        M         35     ACTIVE     DFSK           0.0   \n",
       "900859       0        M         35     ACTIVE      KIA           0.4   \n",
       "\n",
       "             TYPE  REPORTING_DATE_DAYS_LAPSED  LOAN_OPEN_DATE_DAYS_LAPSED  \\\n",
       "143      EMPLOYED                        2030                        2258   \n",
       "247      EMPLOYED                        2030                        3554   \n",
       "308      EMPLOYED                        2030                        3260   \n",
       "350      EMPLOYED                        2030                        2603   \n",
       "465     CORPORATE                        2030                        3464   \n",
       "...           ...                         ...                         ...   \n",
       "900855   EMPLOYED                         724                        1060   \n",
       "900856   EMPLOYED                         724                         725   \n",
       "900857  CORPORATE                         724                         885   \n",
       "900858  CORPORATE                         724                         788   \n",
       "900859   EMPLOYED                         724                        2541   \n",
       "\n",
       "        EXPECTED_CLOSE_DATE_DAYS_LAPSED  CUSTOMER_OPEN_DATE_DAYS_LAPSED  \n",
       "143                                1541                            3022  \n",
       "247                                1723                            3567  \n",
       "308                                1449                            3266  \n",
       "350                                1146                            2608  \n",
       "465                                2033                            7597  \n",
       "...                                 ...                             ...  \n",
       "900855                             -742                            1071  \n",
       "900856                            -1108                             738  \n",
       "900857                              172                             936  \n",
       "900858                            -1016                             817  \n",
       "900859                              719                            2903  \n",
       "\n",
       "[39597 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_value = 'ACCOUNT_NUMBER'\n",
    "target_value = 'BUCKET'\n",
    "down_payment = 'PROGRAM_NAME'\n",
    "income_status = 'PROFESSION'\n",
    "birth_date = 'BIRTH_DATE'\n",
    "dates_todays = ['REPORTING_DATE','LOAN_OPEN_DATE','EXPECTED_CLOSE_DATE','CUSTOMER_OPEN_DATE']\n",
    "\n",
    "file.inicial(pivot_value,birth_date,target_value, down_payment,income_status,dates_todays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_data_cat =['SEX','PROFESSION','CAR_TYPE','TYPE'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The total accuracy using all variable is: 0.8888888888888888',\n",
       " 'Using: SEX Model Developed on Seg 1 (train sample) applied on Seg 1 (test sample):0.8870822041553749',\n",
       " 'Using: SEX Model Developed on Full Population (train sample) applied on Seg 1 (test sample):0.8870822041553749',\n",
       " 'Using: SEX Model Developed on Full Population (train sample) applied on Seg 2 (test sample):0.8930817610062893',\n",
       " 'Using: SEX Model Developed on Seg 2 (train sample) applied on Seg 2 (test sample):0.8930817610062893',\n",
       " 'Using: PROFESSION Model Developed on Seg 1 (train sample) applied on Seg 1 (test sample):0.8886059834500318',\n",
       " 'Using: PROFESSION Model Developed on Full Population (train sample) applied on Seg 1 (test sample):0.8886059834500318',\n",
       " 'Using: PROFESSION Model Developed on Full Population (train sample) applied on Seg 2 (test sample):0.9230769230769231',\n",
       " 'Using: PROFESSION Model Developed on Seg 2 (train sample) applied on Seg 2 (test sample):0.9230769230769231',\n",
       " 'Using: CAR_TYPE Model Developed on Seg 1 (train sample) applied on Seg 1 (test sample):0.9022801302931596',\n",
       " 'Using: CAR_TYPE Model Developed on Full Population (train sample) applied on Seg 1 (test sample):0.9022801302931596',\n",
       " 'Using: CAR_TYPE Model Developed on Full Population (train sample) applied on Seg 2 (test sample):0.8856695379796398',\n",
       " 'Using: CAR_TYPE Model Developed on Seg 2 (train sample) applied on Seg 2 (test sample):0.8856695379796398',\n",
       " 'Using: TYPE Model Developed on Seg 1 (train sample) applied on Seg 1 (test sample):0.8823529411764706',\n",
       " 'Using: TYPE Model Developed on Full Population (train sample) applied on Seg 1 (test sample):0.8823529411764706',\n",
       " 'Using: TYPE Model Developed on Full Population (train sample) applied on Seg 2 (test sample):0.9809523809523809',\n",
       " 'Using: TYPE Model Developed on Seg 2 (train sample) applied on Seg 2 (test sample):0.9809523809523809']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.set_train_cat(target_value,seg_data_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_data_num = ['ORIGINAL_BOOKED_AMOUNT','OUTSTANDING','BIRTH_DATE','DOWN_PAYMENT','REPORTING_DATE_DAYS_LAPSED','LOAN_OPEN_DATE_DAYS_LAPSED','EXPECTED_CLOSE_DATE_DAYS_LAPSED','CUSTOMER_OPEN_DATE_DAYS_LAPSED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The total accuracy using all variable is: 0.8906547997457088',\n",
       " 'Using: ORIGINAL_BOOKED_AMOUNT Model Developed on Seg 1 (train sample) applied on Seg 1 (test sample):0.8573667711598746',\n",
       " 'Using: ORIGINAL_BOOKED_AMOUNT Model Developed on Full Population (train sample) applied on Seg 1 (test sample):0.8573667711598746',\n",
       " 'Using: ORIGINAL_BOOKED_AMOUNT Model Developed on Full Population (train sample) applied on Seg 2 (test sample):0.9133689839572192',\n",
       " 'Using: ORIGINAL_BOOKED_AMOUNT Model Developed on Seg 2 (train sample) applied on Seg 2 (test sample):0.9133689839572192',\n",
       " 'Using: OUTSTANDING Model Developed on Seg 1 (train sample) applied on Seg 1 (test sample):0.8051948051948052',\n",
       " 'Using: OUTSTANDING Model Developed on Full Population (train sample) applied on Seg 1 (test sample):0.8051948051948052',\n",
       " 'Using: OUTSTANDING Model Developed on Full Population (train sample) applied on Seg 2 (test sample):0.9243924392439244',\n",
       " 'Using: OUTSTANDING Model Developed on Seg 2 (train sample) applied on Seg 2 (test sample):0.9243924392439244',\n",
       " 'Using: BIRTH_DATE Model Developed on Seg 1 (train sample) applied on Seg 1 (test sample):0.9149253731343283',\n",
       " 'Using: BIRTH_DATE Model Developed on Full Population (train sample) applied on Seg 1 (test sample):0.9149253731343283',\n",
       " 'Using: BIRTH_DATE Model Developed on Full Population (train sample) applied on Seg 2 (test sample):0.8726467331118494',\n",
       " 'Using: BIRTH_DATE Model Developed on Seg 2 (train sample) applied on Seg 2 (test sample):0.8726467331118494',\n",
       " 'Using: DOWN_PAYMENT Model Developed on Seg 1 (train sample) applied on Seg 1 (test sample):0.9083969465648855',\n",
       " 'Using: DOWN_PAYMENT Model Developed on Full Population (train sample) applied on Seg 1 (test sample):0.9083969465648855',\n",
       " 'Using: DOWN_PAYMENT Model Developed on Full Population (train sample) applied on Seg 2 (test sample):0.8729351969504447',\n",
       " 'Using: DOWN_PAYMENT Model Developed on Seg 2 (train sample) applied on Seg 2 (test sample):0.8729351969504447',\n",
       " 'Using: REPORTING_DATE_DAYS_LAPSED Model Developed on Seg 1 (train sample) applied on Seg 1 (test sample):0.9445277361319341',\n",
       " 'Using: REPORTING_DATE_DAYS_LAPSED Model Developed on Full Population (train sample) applied on Seg 1 (test sample):0.9445277361319341',\n",
       " 'Using: REPORTING_DATE_DAYS_LAPSED Model Developed on Full Population (train sample) applied on Seg 2 (test sample):0.8509933774834437',\n",
       " 'Using: REPORTING_DATE_DAYS_LAPSED Model Developed on Seg 2 (train sample) applied on Seg 2 (test sample):0.8509933774834437',\n",
       " 'Using: LOAN_OPEN_DATE_DAYS_LAPSED Model Developed on Seg 1 (train sample) applied on Seg 1 (test sample):0.9299123904881101',\n",
       " 'Using: LOAN_OPEN_DATE_DAYS_LAPSED Model Developed on Full Population (train sample) applied on Seg 1 (test sample):0.9299123904881101',\n",
       " 'Using: LOAN_OPEN_DATE_DAYS_LAPSED Model Developed on Full Population (train sample) applied on Seg 2 (test sample):0.8475452196382429',\n",
       " 'Using: LOAN_OPEN_DATE_DAYS_LAPSED Model Developed on Seg 2 (train sample) applied on Seg 2 (test sample):0.8475452196382429',\n",
       " 'Using: EXPECTED_CLOSE_DATE_DAYS_LAPSED Model Developed on Seg 1 (train sample) applied on Seg 1 (test sample):0.93854033290653',\n",
       " 'Using: EXPECTED_CLOSE_DATE_DAYS_LAPSED Model Developed on Full Population (train sample) applied on Seg 1 (test sample):0.93854033290653',\n",
       " 'Using: EXPECTED_CLOSE_DATE_DAYS_LAPSED Model Developed on Full Population (train sample) applied on Seg 2 (test sample):0.8396464646464646',\n",
       " 'Using: EXPECTED_CLOSE_DATE_DAYS_LAPSED Model Developed on Seg 2 (train sample) applied on Seg 2 (test sample):0.8396464646464646',\n",
       " 'Using: CUSTOMER_OPEN_DATE_DAYS_LAPSED Model Developed on Seg 1 (train sample) applied on Seg 1 (test sample):0.9362962962962963',\n",
       " 'Using: CUSTOMER_OPEN_DATE_DAYS_LAPSED Model Developed on Full Population (train sample) applied on Seg 1 (test sample):0.9362962962962963',\n",
       " 'Using: CUSTOMER_OPEN_DATE_DAYS_LAPSED Model Developed on Full Population (train sample) applied on Seg 2 (test sample):0.856347438752784',\n",
       " 'Using: CUSTOMER_OPEN_DATE_DAYS_LAPSED Model Developed on Seg 2 (train sample) applied on Seg 2 (test sample):0.856347438752784']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.set_train_num(seg_data_cat,target_value,seg_data_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
