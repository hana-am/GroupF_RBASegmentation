{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+http://github.com/renero/dataset\n",
      "  Cloning http://github.com/renero/dataset to /private/var/folders/wv/yvq0c5md1zj9wnt_vwjs6vpc0000gn/T/pip-req-build-2tejjbt3\n",
      "Requirement already satisfied, skipping upgrade: matplotlib in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from dataset==0.17.1) (3.3.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from dataset==0.17.1) (1.19.2)\n",
      "Requirement already satisfied, skipping upgrade: pandas in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from dataset==0.17.1) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit_learn in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from dataset==0.17.1) (0.23.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from dataset==0.17.1) (1.5.2)\n",
      "Requirement already satisfied, skipping upgrade: seaborn in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from dataset==0.17.1) (0.11.0)\n",
      "Requirement already satisfied, skipping upgrade: sklearn_pandas in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from dataset==0.17.1) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: skrebate in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from dataset==0.17.1) (0.62)\n",
      "Requirement already satisfied, skipping upgrade: statsmodels in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from dataset==0.17.1) (0.12.0)\n",
      "Requirement already satisfied, skipping upgrade: nbsphinx in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from dataset==0.17.1) (0.8.6)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->dataset==0.17.1) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: pillow>=6.2.0 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->dataset==0.17.1) (8.0.1)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->dataset==0.17.1) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->dataset==0.17.1) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->dataset==0.17.1) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2020.06.20 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->dataset==0.17.1) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.3 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from pandas->dataset==0.17.1) (2020.1)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from scikit_learn->dataset==0.17.1) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from scikit_learn->dataset==0.17.1) (0.17.0)\n",
      "Requirement already satisfied, skipping upgrade: patsy>=0.5 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from statsmodels->dataset==0.17.1) (0.5.1)\n",
      "Requirement already satisfied, skipping upgrade: nbformat in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbsphinx->dataset==0.17.1) (5.0.8)\n",
      "Requirement already satisfied, skipping upgrade: sphinx>=1.8 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbsphinx->dataset==0.17.1) (3.2.1)\n",
      "Requirement already satisfied, skipping upgrade: jinja2 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbsphinx->dataset==0.17.1) (2.11.2)\n",
      "Requirement already satisfied, skipping upgrade: nbconvert!=5.4 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbsphinx->dataset==0.17.1) (6.0.7)\n",
      "Requirement already satisfied, skipping upgrade: traitlets in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbsphinx->dataset==0.17.1) (5.0.5)\n",
      "Requirement already satisfied, skipping upgrade: docutils in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbsphinx->dataset==0.17.1) (0.16)\n",
      "Requirement already satisfied, skipping upgrade: six in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->dataset==0.17.1) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-core in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbformat->nbsphinx->dataset==0.17.1) (4.6.3)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema!=2.5.0,>=2.4 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbformat->nbsphinx->dataset==0.17.1) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: ipython-genutils in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbformat->nbsphinx->dataset==0.17.1) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from sphinx>=1.8->nbsphinx->dataset==0.17.1) (20.4)\n",
      "Requirement already satisfied, skipping upgrade: sphinxcontrib-htmlhelp in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from sphinx>=1.8->nbsphinx->dataset==0.17.1) (1.0.3)\n",
      "Requirement already satisfied, skipping upgrade: Pygments>=2.0 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from sphinx>=1.8->nbsphinx->dataset==0.17.1) (2.7.2)\n",
      "Requirement already satisfied, skipping upgrade: babel>=1.3 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from sphinx>=1.8->nbsphinx->dataset==0.17.1) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: imagesize in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from sphinx>=1.8->nbsphinx->dataset==0.17.1) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: alabaster<0.8,>=0.7 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from sphinx>=1.8->nbsphinx->dataset==0.17.1) (0.7.12)\n",
      "Requirement already satisfied, skipping upgrade: requests>=2.5.0 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from sphinx>=1.8->nbsphinx->dataset==0.17.1) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: sphinxcontrib-applehelp in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from sphinx>=1.8->nbsphinx->dataset==0.17.1) (1.0.2)\n",
      "Requirement already satisfied, skipping upgrade: snowballstemmer>=1.1 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from sphinx>=1.8->nbsphinx->dataset==0.17.1) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: sphinxcontrib-devhelp in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from sphinx>=1.8->nbsphinx->dataset==0.17.1) (1.0.2)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from sphinx>=1.8->nbsphinx->dataset==0.17.1) (50.3.1.post20201107)\n",
      "Requirement already satisfied, skipping upgrade: sphinxcontrib-jsmath in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from sphinx>=1.8->nbsphinx->dataset==0.17.1) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: sphinxcontrib-qthelp in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from sphinx>=1.8->nbsphinx->dataset==0.17.1) (1.0.3)\n",
      "Requirement already satisfied, skipping upgrade: sphinxcontrib-serializinghtml in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from sphinx>=1.8->nbsphinx->dataset==0.17.1) (1.1.4)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from jinja2->nbsphinx->dataset==0.17.1) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: entrypoints>=0.2.2 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbconvert!=5.4->nbsphinx->dataset==0.17.1) (0.3)\n",
      "Requirement already satisfied, skipping upgrade: bleach in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbconvert!=5.4->nbsphinx->dataset==0.17.1) (3.2.1)\n",
      "Requirement already satisfied, skipping upgrade: mistune<2,>=0.8.1 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbconvert!=5.4->nbsphinx->dataset==0.17.1) (0.8.4)\n",
      "Requirement already satisfied, skipping upgrade: defusedxml in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbconvert!=5.4->nbsphinx->dataset==0.17.1) (0.6.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied, skipping upgrade: nbclient<0.6.0,>=0.5.0 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbconvert!=5.4->nbsphinx->dataset==0.17.1) (0.5.1)\n",
      "Requirement already satisfied, skipping upgrade: pandocfilters>=1.4.1 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbconvert!=5.4->nbsphinx->dataset==0.17.1) (1.4.3)\n",
      "Requirement already satisfied, skipping upgrade: testpath in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbconvert!=5.4->nbsphinx->dataset==0.17.1) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: jupyterlab-pygments in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbconvert!=5.4->nbsphinx->dataset==0.17.1) (0.1.2)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->nbsphinx->dataset==0.17.1) (0.17.3)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->nbsphinx->dataset==0.17.1) (20.3.0)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.5.0->sphinx>=1.8->nbsphinx->dataset==0.17.1) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.5.0->sphinx>=1.8->nbsphinx->dataset==0.17.1) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.5.0->sphinx>=1.8->nbsphinx->dataset==0.17.1) (1.25.11)\n",
      "Requirement already satisfied, skipping upgrade: webencodings in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from bleach->nbconvert!=5.4->nbsphinx->dataset==0.17.1) (0.5.1)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-client>=6.1.5 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert!=5.4->nbsphinx->dataset==0.17.1) (6.1.7)\n",
      "Requirement already satisfied, skipping upgrade: async-generator in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert!=5.4->nbsphinx->dataset==0.17.1) (1.10)\n",
      "Requirement already satisfied, skipping upgrade: nest-asyncio in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert!=5.4->nbsphinx->dataset==0.17.1) (1.4.2)\n",
      "Requirement already satisfied, skipping upgrade: tornado>=4.1 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert!=5.4->nbsphinx->dataset==0.17.1) (6.0.4)\n",
      "Requirement already satisfied, skipping upgrade: pyzmq>=13 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert!=5.4->nbsphinx->dataset==0.17.1) (19.0.2)\n",
      "Building wheels for collected packages: dataset\n",
      "  Building wheel for dataset (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dataset: filename=dataset-0.17.1-py3-none-any.whl size=22736 sha256=6964129f08674556911c810e225de46fd40dc3e2082ad27f890a2938385604cb\n",
      "  Stored in directory: /private/var/folders/wv/yvq0c5md1zj9wnt_vwjs6vpc0000gn/T/pip-ephem-wheel-cache-t92hogk6/wheels/5e/d1/b3/9ef477d13c9620bcfd5984012b4831ba1a2641562d7b0e6b78\n",
      "Successfully built dataset\n",
      "Installing collected packages: dataset\n",
      "  Attempting uninstall: dataset\n",
      "    Found existing installation: dataset 0.17.1\n",
      "    Uninstalling dataset-0.17.1:\n",
      "      Successfully uninstalled dataset-0.17.1\n",
      "Successfully installed dataset-0.17.1\n",
      "Requirement already satisfied: skrebate in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (0.62)\n",
      "Requirement already satisfied: scipy in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from skrebate) (1.5.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from skrebate) (0.23.2)\n",
      "Requirement already satisfied: numpy in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from skrebate) (1.19.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->skrebate) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->skrebate) (2.1.0)\n",
      "Requirement already satisfied: gplearn in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (0.4.1)\n",
      "Requirement already satisfied: joblib>=0.13.0 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from gplearn) (0.17.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from gplearn) (0.23.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.20.0->gplearn) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.20.0->gplearn) (1.19.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/fergodinez/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.20.0->gplearn) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade git+http://github.com/renero/dataset\n",
    "!pip install skrebate\n",
    "!pip install gplearn\n",
    "\n",
    "from copy import copy\n",
    "from dataset import Dataset\n",
    "from datetime import datetime, date\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import re\n",
    "import math\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiskDataframe():\n",
    "    \n",
    "#-----------------------------------------------------------------------------\n",
    "                        # CLASS INITIALIZATION\n",
    "#----------------------------------------------------------------------------- \n",
    "    def  __init__(self,filename) :\n",
    "        self.data = pd.read_csv(filename)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "                        # RISK BASED APPROACH\n",
    "#-----------------------------------------------------------------------------    \n",
    "    def missing_not_at_random(self, input_vars=[] ):\n",
    "\n",
    "        for var in input_vars:\n",
    "            if var not in self.columns:\n",
    "                print(f\"Variable named {var} not in the dataframe. Review the input variable names\")\n",
    "            return\n",
    "        \n",
    "        if input_vars==[]: columns = self.columns\n",
    "        else: columns = input_vars\n",
    "        missing_value_columns = [column for column in columns if self[column].isnull().values.any()]\n",
    "        print(f\"Missing Not At Random Repport (MNAR) - {', '.join(missing_value_columns) if len(missing_value_columns)>0 else 'No'} variables seem Missing Not at Random, there for we recommend: \\n \\n Thin File Segment Variables (all others variables free of MNAR issue): {', '.join([column for column in columns if column not in missing_value_columns])} \\n \\n Full File Segment Variables: {', '.join(columns)}\")\n",
    "        return\n",
    "        \n",
    "#-----------------------------------------------------------------------------\n",
    "                        # DATA CLEANING\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "    def start (self,piv,birth_date,target,down_payment,income_status,dates_todays) :\n",
    "        self._pivot_unique(piv)\n",
    "        self._clean_target(target)\n",
    "        self._clean(birth_date)\n",
    "        self._down(down_payment)\n",
    "        self._income(income_status)\n",
    "        self._dayslapsed(dates_todays)\n",
    "        return self.data\n",
    "    \n",
    "    #Remove duplicates using the 'pivot' value established by the user\n",
    "    def _pivot_unique (self,piv) :\n",
    "        self.data.drop_duplicates(subset=[piv], keep='last', inplace = True)\n",
    "        return self.data\n",
    "    \n",
    "    #The idea of this analysis is to have a binary bucket \n",
    "    def _clean_target (self,target) :\n",
    "        for i in range(len(self.data.columns)):\n",
    "            tar = str(self.data.columns[i])\n",
    "            if tar == target :\n",
    "                val = np.where(self.data[self.data.columns[i]]>0,1,self.data[self.data.columns[i]])\n",
    "                self.data[self.data.columns[i]] = val\n",
    "        return self.data\n",
    "    \n",
    "    # Getting the agre from the birth date in the dataFrame and cleainig empty spaces\n",
    "    def _clean(self,birth_date) :\n",
    "\n",
    "        data = Dataset.from_dataframe(self.data)\n",
    "        numerical_features = data.numerical_features\n",
    "        categorical_features = data.categorical_features\n",
    "        \n",
    "        # clean numerical values\n",
    "        for i in range(len(self.data.columns)):\n",
    "            empty = self.data[self.data.columns[i]].isna().any()\n",
    "            if empty == True and self.data.columns[i] in numerical_features:\n",
    "                val = self.data[self.data.columns[i]].fillna(self.data[self.data.columns[i]].mean())\n",
    "                self.data[self.data.columns[i]] = val\n",
    "        \n",
    "        # clean categorical values\n",
    "            # fill empty\n",
    "        for i in range(len(self.data.columns)):\n",
    "            empty = self.data[self.data.columns[i]].isna().any()\n",
    "            if empty == True and self.data.columns[i] in categorical_features:\n",
    "                val = self.data[self.data.columns[i]].fillna('UNKNOWN')\n",
    "                self.data[self.data.columns[i]] = val\n",
    "            \n",
    "            # upper case\n",
    "        for i in range(len(self.data.columns)):\n",
    "            if self.data.columns[i] in categorical_features:\n",
    "                val = self.data[self.data.columns[i]].str.upper()\n",
    "                self.data[self.data.columns[i]] = val\n",
    "        \n",
    "        # if birth date, return age\n",
    "        def age(born):\n",
    "            while True:\n",
    "                try:\n",
    "                    born = datetime.datetime.strptime(born, \"%Y-%m-%d\").date()\n",
    "                    today = date.today()\n",
    "                    return today.year - born.year - ((today.month, today.day) < (born.month, born.day))\n",
    "                except ValueError:\n",
    "                    return 'UNKNOWN'\n",
    "        for i in range(len(self.data.columns)):\n",
    "            dateb = str(self.data.columns[i])\n",
    "            if self.data.columns[i] in categorical_features and dateb == birth_date :\n",
    "                val = self.data[self.data.columns[i]].apply(age)\n",
    "                self.data[self.data.columns[i]] = val\n",
    "\n",
    "        return self.data\n",
    "\n",
    "    # The down Payment has to mean something in order to be useful in the Model. We get the % in each value. Also we separate between individuals and corporate\n",
    "    \n",
    "    def _down(self,down_payment) :\n",
    "        def pay(payment) :\n",
    "            y = re.findall('\\d+', payment)\n",
    "            if len(y) > 0 :\n",
    "                result = int(y[0])/100\n",
    "            else:\n",
    "                result = 0\n",
    "            return result\n",
    "        \n",
    "        def ty(types) :\n",
    "            if 'EMPLOYED' in types :\n",
    "                return 'EMPLOYED'\n",
    "            else:\n",
    "                return 'CORPORATE'\n",
    "        \n",
    "        self.data[\"DOWN_PAYMENT\"] = None\n",
    "        self.data[\"TYPE\"] = None\n",
    "        val = self.data[down_payment].apply(pay)\n",
    "        self.data[\"DOWN_PAYMENT\"] = val\n",
    "        \n",
    "        val = self.data[down_payment].apply(ty)\n",
    "        self.data[\"TYPE\"] = val\n",
    "        self.data.drop(columns = [down_payment], inplace = True)\n",
    "        \n",
    "        return self.data\n",
    "    \n",
    "    # There are too many jobs, we can isolate between those who get some income and unemployed guys\n",
    "    def _income (self,income_status) :\n",
    "        def income(incomes) :\n",
    "            if 'UNEMPLOYED' in incomes :\n",
    "                return 'UNEMPLOYED'\n",
    "            else:\n",
    "                return 'ACTIVE' \n",
    "       \n",
    "        val = self.data[income_status].apply(income)\n",
    "        self.data[income_status] = val\n",
    "    \n",
    "    # Dates are not useful for the model, we need numerical values.\n",
    "    \n",
    "    def _dayslapsed (self,dates_todays):\n",
    "        def daily(dai) :\n",
    "            change = datetime.datetime.strptime(dai, \"%Y-%m-%d\").date()\n",
    "            today = date.today()\n",
    "            delta = today - change\n",
    "            return delta.days\n",
    "        \n",
    "        for i in range(len(dates_todays)):\n",
    "            self.data[dates_todays[i]+'_DAYS_LAPSED'] = None\n",
    "            val = self.data[dates_todays[i]].apply(daily)\n",
    "            self.data[dates_todays[i]+'_DAYS_LAPSED'] = val\n",
    "            self.data.drop(columns = [dates_todays[i]], inplace = True)\n",
    "            \n",
    "#-----------------------------------------------------------------------------\n",
    "                        # DATA ANALYSIS\n",
    "#-----------------------------------------------------------------------------\n",
    "        #-----------------------------------------------------------------------------\n",
    "                        # CATEGORICAL VARIABLES ANALYSIS\n",
    "        #-----------------------------------------------------------------------------\n",
    "    \n",
    "    def set_train_cat (self,target_value,seg_data):\n",
    "        \n",
    "        df_random_sample, _ = train_test_split(self.data, test_size=0.90)\n",
    "        \n",
    "        \n",
    "        def get_specific_columns(df_random_sample, data_types, to_ignore = list(), ignore_target = False):\n",
    "            columns = df_random_sample.select_dtypes(include=data_types).columns\n",
    "            if ignore_target:\n",
    "                columns = filter(lambda x: x not in to_ignore, list(columns))\n",
    "            return list(columns)\n",
    "        \n",
    "        all_numeric_variables = get_specific_columns(df_random_sample, [\"float64\", \"int64\"], [target_value], ignore_target = True)\n",
    "        \n",
    "        splitter = train_test_split\n",
    "        df_train, df_test = splitter(df_random_sample, test_size = 0.2, random_state = 42)\n",
    "        \n",
    "        X_train = df_train[all_numeric_variables]\n",
    "        y_train = df_train[target_value]\n",
    "        \n",
    "        X_test = df_test[all_numeric_variables]\n",
    "        y_test = df_test[target_value]\n",
    "        \n",
    "        method = LogisticRegression(random_state=0)\n",
    "        fitted_full_model = method.fit(X_train, y_train)\n",
    "        y_pred = fitted_full_model.predict(X_test)\n",
    "        \n",
    "        # Result accuracy all model\n",
    "        full_model = accuracy_score(y_test, y_pred)\n",
    "        result_full_model_etal =  [\"The total accuracy using all variable and Logistic regression is: \" + str(full_model)]\n",
    "        \n",
    "        conclusion_model = []\n",
    "        \n",
    "        for seg in range(len(seg_data)):\n",
    "            \n",
    "            max_value_seg = self.data[seg_data[seg]].value_counts().idxmax()\n",
    "            \n",
    "            # set dataframes of train and test\n",
    "            \n",
    "            df_train_seg1 = df_train[df_random_sample[seg_data[seg]] == max_value_seg]\n",
    "            df_train_seg2 = df_train[df_random_sample[seg_data[seg]] != max_value_seg]\n",
    "            df_test_seg1 = df_test[df_random_sample[seg_data[seg]] == max_value_seg]\n",
    "            df_test_seg2 = df_test[df_random_sample[seg_data[seg]] != max_value_seg]\n",
    "            \n",
    "            #getting results seg 1 vs seg 1\n",
    "           \n",
    "            X_train_seg1 = df_train_seg1[all_numeric_variables]\n",
    "            y_train_seg1 = df_train_seg1[target_value]\n",
    "            X_test_seg1 = df_test_seg1[all_numeric_variables]\n",
    "            y_test_seg1 = df_test_seg1[target_value]\n",
    "            \n",
    "            fitted_model_seg1 = method.fit(X_train_seg1, y_train_seg1)\n",
    "            \n",
    "            def GINI(y_test, y_pred_probadbility):\n",
    "                from sklearn.metrics import roc_curve, auc\n",
    "                fpr, tpr, thresholds = roc_curve(y_test, y_pred_probadbility)\n",
    "                roc_auc = auc(fpr, tpr)\n",
    "                GINI = (2 * roc_auc) - 1\n",
    "                return(GINI)\n",
    "            \n",
    "            y_pred_seg1_proba = fitted_model_seg1.predict_proba(X_test_seg1)[:,1]\n",
    "            y_pred_seg1_fullmodel_proba = fitted_full_model.predict_proba(X_test_seg1)[:,1]\n",
    "            \n",
    "            \n",
    "            result_full_model_etal.append(\"Using: \" + seg_data[seg] + \" GINI Full Model Seg1: \"+ str(GINI(y_test_seg1, y_pred_seg1_proba)*100)+\"%\")\n",
    "            result_full_model_etal.append(\"Using: \" + seg_data[seg] + \" GINI Segmented Model Seg1: \"+ str(GINI(y_test_seg1, y_pred_seg1_fullmodel_proba)*100)+\"%\")\n",
    "            \n",
    "            #getting results seg 2 vs seg 2\n",
    "\n",
    "            \n",
    "            X_train_seg2 = df_train_seg2[all_numeric_variables]\n",
    "            y_train_seg2 = df_train_seg2[target_value]\n",
    "            X_test_seg2 = df_test_seg2[all_numeric_variables]\n",
    "            y_test_seg2 = df_test_seg2[target_value]\n",
    "            fitted_model_seg2 = method.fit(X_train_seg2, y_train_seg2)\n",
    "            y_pred_seg2 = fitted_model_seg2.predict(X_test_seg2)\n",
    "            y_pred_seg2_fullmodel = fitted_full_model.predict(X_test_seg2)\n",
    "            \n",
    "            y_pred_seg2_proba = fitted_model_seg1.predict_proba(X_test_seg2)[:,1]\n",
    "            y_pred_seg2_fullmodel_proba = fitted_full_model.predict_proba(X_test_seg2)[:,1]\n",
    "            \n",
    "            result_full_model_etal.append(\"Using: \" + seg_data[seg] +\" GINI Full Model Seg2: \" + str(GINI(y_test_seg2, y_pred_seg2_proba)*100) +\"%\")\n",
    "            result_full_model_etal.append(\"Using: \" + seg_data[seg] +\" GINI Segmented Model Seg2:\" + str(GINI(y_test_seg2, y_pred_seg2_fullmodel_proba)*100)+\"%\") \n",
    "                    \n",
    "            if GINI(y_test_seg1, y_pred_seg1_proba)*100 < 20 or GINI(y_test_seg2, y_pred_seg2_proba)*100 < 20:\n",
    "                \n",
    "                conclusion_model.append(\"After analysis, we did not find a good split using: \" + seg_data[seg])\n",
    "            else:\n",
    "                conclusion_model.append(\"After analysis, we find a good split using: \" + seg_data[seg] + \" set at: \" + str(max_value_seg))\n",
    "        \n",
    "        return result_full_model_etal, conclusion_model\n",
    "    \n",
    "        #-----------------------------------------------------------------------------\n",
    "                        # ENCODING\n",
    "        #-----------------------------------------------------------------------------\n",
    "    \n",
    "    def encod (self, seg_data_cat):\n",
    "        data = Dataset.from_dataframe(self.data)\n",
    "        for seg in range(len(seg_data_cat)):\n",
    "            data.onehot_encode(seg_data_cat[seg])\n",
    "            data.drop_columns(seg_data_cat[seg])\n",
    "        \n",
    "        self.data = data.features\n",
    "        \n",
    "        return self.data\n",
    "    \n",
    "        #-----------------------------------------------------------------------------\n",
    "                        # NUMERICAL VARIABLES ANALYSIS\n",
    "        #-----------------------------------------------------------------------------\n",
    "    \n",
    "    def set_train_num (self,seg_data_cat,target_value,seg_data_num): \n",
    "        \n",
    "        # Lets get rid of Unknown values so that we can have means in each column\n",
    "        for dro in range(len(seg_data_num)):\n",
    "            self.data.drop(self.data.index[self.data[seg_data_num[dro]] == 'UNKNOWN'], inplace = True)\n",
    "        \n",
    "        def get_specific_columns(df_random_sample, data_types, to_ignore = list(), ignore_target = False):\n",
    "            columns = df_random_sample.select_dtypes(include=data_types).columns\n",
    "            if ignore_target:\n",
    "                columns = filter(lambda x: x not in to_ignore, list(columns))\n",
    "            return list(columns)\n",
    "        \n",
    "\n",
    "        df_random_sample, _ = train_test_split(self.data, test_size=0.90)\n",
    "        all_numeric_variables = get_specific_columns(df_random_sample, [\"float64\", \"int64\"], [target_value], ignore_target = True)\n",
    "        \n",
    "        splitter = train_test_split\n",
    "        df_train, df_test = splitter(df_random_sample, test_size = 0.2, random_state = 42)\n",
    "        \n",
    "        result_full_model_etal = []\n",
    "        \n",
    "        X_train = df_train[all_numeric_variables]\n",
    "        y_train = df_train[target_value]\n",
    "        \n",
    "        X_test = df_test[all_numeric_variables]\n",
    "        y_test = df_test[target_value]\n",
    "        \n",
    "        method = LogisticRegression(random_state=0)\n",
    "        fitted_full_model = method.fit(X_train, y_train)\n",
    "        y_pred = fitted_full_model.predict(X_test)\n",
    "        \n",
    "        full_model = accuracy_score(y_test, y_pred)\n",
    "        result_full_model_etal =  [\"The total accuracy using all variable and Logistic regression is: \" + str(full_model)]\n",
    "        \n",
    "        conclusion_model = []\n",
    "       \n",
    "        for seg in range(len(seg_data_num)):\n",
    "            \n",
    "            mean_value_seg = self.data[seg_data_num[seg]].mean()\n",
    "            \n",
    "            # set dataframes of train and test\n",
    "            \n",
    "            df_train_seg1 = df_train[df_random_sample[seg_data_num[seg]] >= mean_value_seg]\n",
    "            df_train_seg2 = df_train[df_random_sample[seg_data_num[seg]] < mean_value_seg]\n",
    "            df_test_seg1 = df_test[df_random_sample[seg_data_num[seg]] >=  mean_value_seg]\n",
    "            df_test_seg2 = df_test[df_random_sample[seg_data_num[seg]] < mean_value_seg]\n",
    "            \n",
    "            #getting results seg 1 vs seg 1\n",
    "           \n",
    "            X_train_seg1 = df_train_seg1[all_numeric_variables]\n",
    "            y_train_seg1 = df_train_seg1[target_value]\n",
    "            X_test_seg1 = df_test_seg1[all_numeric_variables]\n",
    "            y_test_seg1 = df_test_seg1[target_value]\n",
    "            \n",
    "            fitted_model_seg1 = method.fit(X_train_seg1, y_train_seg1)\n",
    "            \n",
    "            def GINI(y_test, y_pred_probadbility):\n",
    "                from sklearn.metrics import roc_curve, auc\n",
    "                fpr, tpr, thresholds = roc_curve(y_test, y_pred_probadbility)\n",
    "                roc_auc = auc(fpr, tpr)\n",
    "                GINI = (2 * roc_auc) - 1\n",
    "                return(GINI)\n",
    "            \n",
    "            y_pred_seg1_proba = fitted_model_seg1.predict_proba(X_test_seg1)[:,1]\n",
    "            y_pred_seg1_fullmodel_proba = fitted_full_model.predict_proba(X_test_seg1)[:,1]\n",
    "            \n",
    "            \n",
    "            result_full_model_etal.append(\"Using: \" + seg_data_num[seg] + \" GINI Full Model Seg1: \"+ str(GINI(y_test_seg1, y_pred_seg1_proba)*100)+\"%\")\n",
    "            result_full_model_etal.append(\"Using: \" + seg_data_num[seg] + \" GINI Segmented Model Seg1: \"+ str(GINI(y_test_seg1, y_pred_seg1_fullmodel_proba)*100)+\"%\")\n",
    "            \n",
    "            #getting results seg 2 vs seg 2\n",
    "\n",
    "            \n",
    "            X_train_seg2 = df_train_seg2[all_numeric_variables]\n",
    "            y_train_seg2 = df_train_seg2[target_value]\n",
    "            X_test_seg2 = df_test_seg2[all_numeric_variables]\n",
    "            y_test_seg2 = df_test_seg2[target_value]\n",
    "            fitted_model_seg2 = method.fit(X_train_seg2, y_train_seg2)\n",
    "            y_pred_seg2 = fitted_model_seg2.predict(X_test_seg2)\n",
    "            y_pred_seg2_fullmodel = fitted_full_model.predict(X_test_seg2)\n",
    "            \n",
    "            y_pred_seg2_proba = fitted_model_seg1.predict_proba(X_test_seg2)[:,1]\n",
    "            y_pred_seg2_fullmodel_proba = fitted_full_model.predict_proba(X_test_seg2)[:,1]\n",
    "            \n",
    "            result_full_model_etal.append(\"Using: \" + seg_data_num[seg] +\" GINI Full Model Seg2: \" + str(GINI(y_test_seg2, y_pred_seg2_proba)*100) +\"%\")\n",
    "            result_full_model_etal.append(\"Using: \" + seg_data_num[seg] +\" GINI Segmented Model Seg2: \" + str(GINI(y_test_seg2, y_pred_seg2_fullmodel_proba)*100)+\"%\") \n",
    "            \n",
    "            if GINI(y_test_seg1, y_pred_seg1_proba)*100 < 20 or GINI(y_test_seg2, y_pred_seg2_proba)*100 < 20:\n",
    "                conclusion_model.append(\"After analysis, we did not find a good split using: \" + seg_data_num[seg])\n",
    "            else:\n",
    "                conclusion_model.append(\"After analysis, we find a good split using: \" + seg_data_num[seg] + \" set at: \" + str(mean_value_seg))\n",
    "        \n",
    "                \n",
    "        return result_full_model_etal, conclusion_model\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "                        # DATA VISUALIZATION\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "    def plot_risk (self,variable):\n",
    "        plt.hist(self.data[variable], color='g', label='Ideal')\n",
    "        print(self.data.describe())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = RiskDataframe('AUTO_LOANS_DATA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACCOUNT_NUMBER</th>\n",
       "      <th>CUSTOMER_ID</th>\n",
       "      <th>ORIGINAL_BOOKED_AMOUNT</th>\n",
       "      <th>OUTSTANDING</th>\n",
       "      <th>BUCKET</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BIRTH_DATE</th>\n",
       "      <th>PROFESSION</th>\n",
       "      <th>CAR_TYPE</th>\n",
       "      <th>DOWN_PAYMENT</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>REPORTING_DATE_DAYS_LAPSED</th>\n",
       "      <th>LOAN_OPEN_DATE_DAYS_LAPSED</th>\n",
       "      <th>EXPECTED_CLOSE_DATE_DAYS_LAPSED</th>\n",
       "      <th>CUSTOMER_OPEN_DATE_DAYS_LAPSED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>140500.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>EMPLOYED</td>\n",
       "      <td>2044</td>\n",
       "      <td>2272</td>\n",
       "      <td>1555</td>\n",
       "      <td>3036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>248</td>\n",
       "      <td>248</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>37</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>EMPLOYED</td>\n",
       "      <td>2044</td>\n",
       "      <td>3568</td>\n",
       "      <td>1737</td>\n",
       "      <td>3581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>309</td>\n",
       "      <td>307</td>\n",
       "      <td>65500.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>44</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>EMPLOYED</td>\n",
       "      <td>2044</td>\n",
       "      <td>3274</td>\n",
       "      <td>1463</td>\n",
       "      <td>3280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>351</td>\n",
       "      <td>349</td>\n",
       "      <td>44500.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>40</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>EMPLOYED</td>\n",
       "      <td>2044</td>\n",
       "      <td>2617</td>\n",
       "      <td>1160</td>\n",
       "      <td>2622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>466</td>\n",
       "      <td>12</td>\n",
       "      <td>93000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CORPORATE</td>\n",
       "      <td>2044</td>\n",
       "      <td>3478</td>\n",
       "      <td>2047</td>\n",
       "      <td>7611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900855</th>\n",
       "      <td>36547</td>\n",
       "      <td>35528</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>78956.52</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>27</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>GELORY</td>\n",
       "      <td>0.5</td>\n",
       "      <td>EMPLOYED</td>\n",
       "      <td>738</td>\n",
       "      <td>1074</td>\n",
       "      <td>-728</td>\n",
       "      <td>1085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900856</th>\n",
       "      <td>39597</td>\n",
       "      <td>38396</td>\n",
       "      <td>92500.0</td>\n",
       "      <td>92826.06</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>44</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>GELORY</td>\n",
       "      <td>0.5</td>\n",
       "      <td>EMPLOYED</td>\n",
       "      <td>738</td>\n",
       "      <td>739</td>\n",
       "      <td>-1094</td>\n",
       "      <td>752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900857</th>\n",
       "      <td>38016</td>\n",
       "      <td>36905</td>\n",
       "      <td>140250.0</td>\n",
       "      <td>114919.47</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>41</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>NISSAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CORPORATE</td>\n",
       "      <td>738</td>\n",
       "      <td>899</td>\n",
       "      <td>186</td>\n",
       "      <td>950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900858</th>\n",
       "      <td>38899</td>\n",
       "      <td>37739</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>101714.25</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>DFSK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CORPORATE</td>\n",
       "      <td>738</td>\n",
       "      <td>802</td>\n",
       "      <td>-1002</td>\n",
       "      <td>831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900859</th>\n",
       "      <td>4350</td>\n",
       "      <td>4307</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>KIA</td>\n",
       "      <td>0.4</td>\n",
       "      <td>EMPLOYED</td>\n",
       "      <td>738</td>\n",
       "      <td>2555</td>\n",
       "      <td>733</td>\n",
       "      <td>2917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39597 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACCOUNT_NUMBER  CUSTOMER_ID  ORIGINAL_BOOKED_AMOUNT  OUTSTANDING  \\\n",
       "143                144          144                140500.0         0.00   \n",
       "247                248          248                 70000.0         0.00   \n",
       "308                309          307                 65500.0         0.00   \n",
       "350                351          349                 44500.0         0.00   \n",
       "465                466           12                 93000.0         0.00   \n",
       "...                ...          ...                     ...          ...   \n",
       "900855           36547        35528                 90000.0     78956.52   \n",
       "900856           39597        38396                 92500.0     92826.06   \n",
       "900857           38016        36905                140250.0    114919.47   \n",
       "900858           38899        37739                105000.0    101714.25   \n",
       "900859            4350         4307                120000.0         0.00   \n",
       "\n",
       "        BUCKET      SEX BIRTH_DATE PROFESSION CAR_TYPE  DOWN_PAYMENT  \\\n",
       "143          0        M         39     ACTIVE  UNKNOWN           0.5   \n",
       "247          1        F         37     ACTIVE  UNKNOWN           0.5   \n",
       "308          0        M         44     ACTIVE  UNKNOWN           0.5   \n",
       "350          1        M         40     ACTIVE  UNKNOWN           0.5   \n",
       "465          0  UNKNOWN    UNKNOWN     ACTIVE  UNKNOWN           0.0   \n",
       "...        ...      ...        ...        ...      ...           ...   \n",
       "900855       0        M         27     ACTIVE   GELORY           0.5   \n",
       "900856       0        F         44     ACTIVE   GELORY           0.5   \n",
       "900857       0        M         41     ACTIVE   NISSAN           0.0   \n",
       "900858       0        M         35     ACTIVE     DFSK           0.0   \n",
       "900859       0        M         35     ACTIVE      KIA           0.4   \n",
       "\n",
       "             TYPE  REPORTING_DATE_DAYS_LAPSED  LOAN_OPEN_DATE_DAYS_LAPSED  \\\n",
       "143      EMPLOYED                        2044                        2272   \n",
       "247      EMPLOYED                        2044                        3568   \n",
       "308      EMPLOYED                        2044                        3274   \n",
       "350      EMPLOYED                        2044                        2617   \n",
       "465     CORPORATE                        2044                        3478   \n",
       "...           ...                         ...                         ...   \n",
       "900855   EMPLOYED                         738                        1074   \n",
       "900856   EMPLOYED                         738                         739   \n",
       "900857  CORPORATE                         738                         899   \n",
       "900858  CORPORATE                         738                         802   \n",
       "900859   EMPLOYED                         738                        2555   \n",
       "\n",
       "        EXPECTED_CLOSE_DATE_DAYS_LAPSED  CUSTOMER_OPEN_DATE_DAYS_LAPSED  \n",
       "143                                1555                            3036  \n",
       "247                                1737                            3581  \n",
       "308                                1463                            3280  \n",
       "350                                1160                            2622  \n",
       "465                                2047                            7611  \n",
       "...                                 ...                             ...  \n",
       "900855                             -728                            1085  \n",
       "900856                            -1094                             752  \n",
       "900857                              186                             950  \n",
       "900858                            -1002                             831  \n",
       "900859                              733                            2917  \n",
       "\n",
       "[39597 rows x 15 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_value = 'ACCOUNT_NUMBER'\n",
    "target_value = 'BUCKET'\n",
    "down_payment = 'PROGRAM_NAME'\n",
    "income_status = 'PROFESSION'\n",
    "birth_date = 'BIRTH_DATE'\n",
    "dates_todays = ['REPORTING_DATE','LOAN_OPEN_DATE','EXPECTED_CLOSE_DATE','CUSTOMER_OPEN_DATE']\n",
    "\n",
    "file.start(pivot_value,birth_date,target_value, down_payment,income_status,dates_todays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_data_cat =['SEX','PROFESSION','CAR_TYPE','TYPE'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['The total accuracy using all variable and Logistic regression is: 0.9027777777777778',\n",
       "  'Using: SEX GINI Full Model Seg1: 27.55821078431373%',\n",
       "  'Using: SEX GINI Segmented Model Seg1: 27.55821078431373%',\n",
       "  'Using: SEX GINI Full Model Seg2: 9.700644183402796%',\n",
       "  'Using: SEX GINI Segmented Model Seg2:9.700644183402796%',\n",
       "  'Using: PROFESSION GINI Full Model Seg1: 20.002204302062854%',\n",
       "  'Using: PROFESSION GINI Segmented Model Seg1: 20.002204302062854%',\n",
       "  'Using: PROFESSION GINI Full Model Seg2: nan%',\n",
       "  'Using: PROFESSION GINI Segmented Model Seg2:nan%',\n",
       "  'Using: CAR_TYPE GINI Full Model Seg1: 20.236686390532554%',\n",
       "  'Using: CAR_TYPE GINI Segmented Model Seg1: 20.236686390532554%',\n",
       "  'Using: CAR_TYPE GINI Full Model Seg2: 18.942307692307715%',\n",
       "  'Using: CAR_TYPE GINI Segmented Model Seg2:18.942307692307715%',\n",
       "  'Using: TYPE GINI Full Model Seg1: 22.65356265356264%',\n",
       "  'Using: TYPE GINI Segmented Model Seg1: 22.65356265356264%',\n",
       "  'Using: TYPE GINI Full Model Seg2: -39.39393939393939%',\n",
       "  'Using: TYPE GINI Segmented Model Seg2:-39.39393939393939%'],\n",
       " ['After analysis, we did not find a good split using: SEX',\n",
       "  'After analysis, we find a good split using: PROFESSION set at: ACTIVE',\n",
       "  'After analysis, we did not find a good split using: CAR_TYPE',\n",
       "  'After analysis, we did not find a good split using: TYPE'])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.set_train_cat(target_value,seg_data_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_data_num = ['ORIGINAL_BOOKED_AMOUNT','OUTSTANDING','BIRTH_DATE','DOWN_PAYMENT','REPORTING_DATE_DAYS_LAPSED','LOAN_OPEN_DATE_DAYS_LAPSED','EXPECTED_CLOSE_DATE_DAYS_LAPSED','CUSTOMER_OPEN_DATE_DAYS_LAPSED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACCOUNT_NUMBER</th>\n",
       "      <th>BIRTH_DATE</th>\n",
       "      <th>BUCKET</th>\n",
       "      <th>CAR_TYPE_AUDI</th>\n",
       "      <th>CAR_TYPE_BAIC</th>\n",
       "      <th>CAR_TYPE_BMW</th>\n",
       "      <th>CAR_TYPE_BRILLIANCE</th>\n",
       "      <th>CAR_TYPE_BYD</th>\n",
       "      <th>CAR_TYPE_CARRY</th>\n",
       "      <th>CAR_TYPE_CHANA</th>\n",
       "      <th>...</th>\n",
       "      <th>ORIGINAL_BOOKED_AMOUNT</th>\n",
       "      <th>OUTSTANDING</th>\n",
       "      <th>PROFESSION_ACTIVE</th>\n",
       "      <th>PROFESSION_UNEMPLOYED</th>\n",
       "      <th>REPORTING_DATE_DAYS_LAPSED</th>\n",
       "      <th>SEX_F</th>\n",
       "      <th>SEX_M</th>\n",
       "      <th>SEX_UNKNOWN</th>\n",
       "      <th>TYPE_CORPORATE</th>\n",
       "      <th>TYPE_EMPLOYED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>144.0</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>140500.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2044.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>248.0</td>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2044.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>309.0</td>\n",
       "      <td>44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>65500.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2044.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>351.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44500.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2044.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>466.0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>93000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2044.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900855</th>\n",
       "      <td>36547.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>78956.52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>738.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900856</th>\n",
       "      <td>39597.0</td>\n",
       "      <td>44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>92500.0</td>\n",
       "      <td>92826.06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>738.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900857</th>\n",
       "      <td>38016.0</td>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>140250.0</td>\n",
       "      <td>114919.47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>738.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900858</th>\n",
       "      <td>38899.0</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>101714.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>738.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900859</th>\n",
       "      <td>4350.0</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>738.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39597 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACCOUNT_NUMBER BIRTH_DATE  BUCKET  CAR_TYPE_AUDI  CAR_TYPE_BAIC  \\\n",
       "143              144.0         39     0.0            0.0            0.0   \n",
       "247              248.0         37     1.0            0.0            0.0   \n",
       "308              309.0         44     0.0            0.0            0.0   \n",
       "350              351.0         40     1.0            0.0            0.0   \n",
       "465              466.0    UNKNOWN     0.0            0.0            0.0   \n",
       "...                ...        ...     ...            ...            ...   \n",
       "900855         36547.0         27     0.0            0.0            0.0   \n",
       "900856         39597.0         44     0.0            0.0            0.0   \n",
       "900857         38016.0         41     0.0            0.0            0.0   \n",
       "900858         38899.0         35     0.0            0.0            0.0   \n",
       "900859          4350.0         35     0.0            0.0            0.0   \n",
       "\n",
       "        CAR_TYPE_BMW  CAR_TYPE_BRILLIANCE  CAR_TYPE_BYD  CAR_TYPE_CARRY  \\\n",
       "143              0.0                  0.0           0.0             0.0   \n",
       "247              0.0                  0.0           0.0             0.0   \n",
       "308              0.0                  0.0           0.0             0.0   \n",
       "350              0.0                  0.0           0.0             0.0   \n",
       "465              0.0                  0.0           0.0             0.0   \n",
       "...              ...                  ...           ...             ...   \n",
       "900855           0.0                  0.0           0.0             0.0   \n",
       "900856           0.0                  0.0           0.0             0.0   \n",
       "900857           0.0                  0.0           0.0             0.0   \n",
       "900858           0.0                  0.0           0.0             0.0   \n",
       "900859           0.0                  0.0           0.0             0.0   \n",
       "\n",
       "        CAR_TYPE_CHANA  ...  ORIGINAL_BOOKED_AMOUNT  OUTSTANDING  \\\n",
       "143                0.0  ...                140500.0         0.00   \n",
       "247                0.0  ...                 70000.0         0.00   \n",
       "308                0.0  ...                 65500.0         0.00   \n",
       "350                0.0  ...                 44500.0         0.00   \n",
       "465                0.0  ...                 93000.0         0.00   \n",
       "...                ...  ...                     ...          ...   \n",
       "900855             0.0  ...                 90000.0     78956.52   \n",
       "900856             0.0  ...                 92500.0     92826.06   \n",
       "900857             0.0  ...                140250.0    114919.47   \n",
       "900858             0.0  ...                105000.0    101714.25   \n",
       "900859             0.0  ...                120000.0         0.00   \n",
       "\n",
       "        PROFESSION_ACTIVE  PROFESSION_UNEMPLOYED  REPORTING_DATE_DAYS_LAPSED  \\\n",
       "143                   1.0                    0.0                      2044.0   \n",
       "247                   1.0                    0.0                      2044.0   \n",
       "308                   1.0                    0.0                      2044.0   \n",
       "350                   1.0                    0.0                      2044.0   \n",
       "465                   1.0                    0.0                      2044.0   \n",
       "...                   ...                    ...                         ...   \n",
       "900855                1.0                    0.0                       738.0   \n",
       "900856                1.0                    0.0                       738.0   \n",
       "900857                1.0                    0.0                       738.0   \n",
       "900858                1.0                    0.0                       738.0   \n",
       "900859                1.0                    0.0                       738.0   \n",
       "\n",
       "        SEX_F  SEX_M  SEX_UNKNOWN  TYPE_CORPORATE  TYPE_EMPLOYED  \n",
       "143       0.0    1.0          0.0             0.0            1.0  \n",
       "247       1.0    0.0          0.0             0.0            1.0  \n",
       "308       0.0    1.0          0.0             0.0            1.0  \n",
       "350       0.0    1.0          0.0             0.0            1.0  \n",
       "465       0.0    0.0          1.0             1.0            0.0  \n",
       "...       ...    ...          ...             ...            ...  \n",
       "900855    0.0    1.0          0.0             0.0            1.0  \n",
       "900856    1.0    0.0          0.0             0.0            1.0  \n",
       "900857    0.0    1.0          0.0             1.0            0.0  \n",
       "900858    0.0    1.0          0.0             1.0            0.0  \n",
       "900859    0.0    1.0          0.0             0.0            1.0  \n",
       "\n",
       "[39597 rows x 79 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.encod(seg_data_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['The total accuracy using all variable and Logistic regression is: 0.8831003811944091',\n",
       "  'Using: ORIGINAL_BOOKED_AMOUNT GINI Full Model Seg1: 36.84004309922617%',\n",
       "  'Using: ORIGINAL_BOOKED_AMOUNT GINI Segmented Model Seg1: 36.84004309922617%',\n",
       "  'Using: ORIGINAL_BOOKED_AMOUNT GINI Full Model Seg2: 28.980919722148933%',\n",
       "  'Using: ORIGINAL_BOOKED_AMOUNT GINI Segmented Model Seg2: 28.980919722148933%',\n",
       "  'Using: OUTSTANDING GINI Full Model Seg1: 31.583011583011576%',\n",
       "  'Using: OUTSTANDING GINI Segmented Model Seg1: 31.583011583011576%',\n",
       "  'Using: OUTSTANDING GINI Full Model Seg2: 30.070588235294117%',\n",
       "  'Using: OUTSTANDING GINI Segmented Model Seg2: 30.070588235294117%',\n",
       "  'Using: BIRTH_DATE GINI Full Model Seg1: 32.332089552238806%',\n",
       "  'Using: BIRTH_DATE GINI Segmented Model Seg1: 32.332089552238806%',\n",
       "  'Using: BIRTH_DATE GINI Full Model Seg2: 29.175925925925927%',\n",
       "  'Using: BIRTH_DATE GINI Segmented Model Seg2: 29.175925925925927%',\n",
       "  'Using: DOWN_PAYMENT GINI Full Model Seg1: 26.722058429375515%',\n",
       "  'Using: DOWN_PAYMENT GINI Segmented Model Seg1: 26.722058429375515%',\n",
       "  'Using: DOWN_PAYMENT GINI Full Model Seg2: 32.812037201587586%',\n",
       "  'Using: DOWN_PAYMENT GINI Segmented Model Seg2: 32.812037201587586%',\n",
       "  'Using: REPORTING_DATE_DAYS_LAPSED GINI Full Model Seg1: 12.260015117157973%',\n",
       "  'Using: REPORTING_DATE_DAYS_LAPSED GINI Segmented Model Seg1: 12.260015117157973%',\n",
       "  'Using: REPORTING_DATE_DAYS_LAPSED GINI Full Model Seg2: 28.873239436619702%',\n",
       "  'Using: REPORTING_DATE_DAYS_LAPSED GINI Segmented Model Seg2: 28.873239436619702%',\n",
       "  'Using: LOAN_OPEN_DATE_DAYS_LAPSED GINI Full Model Seg1: 30.93982258451209%',\n",
       "  'Using: LOAN_OPEN_DATE_DAYS_LAPSED GINI Segmented Model Seg1: 30.93982258451209%',\n",
       "  'Using: LOAN_OPEN_DATE_DAYS_LAPSED GINI Full Model Seg2: 37.60553081167322%',\n",
       "  'Using: LOAN_OPEN_DATE_DAYS_LAPSED GINI Segmented Model Seg2: 37.60553081167322%',\n",
       "  'Using: EXPECTED_CLOSE_DATE_DAYS_LAPSED GINI Full Model Seg1: 27.958532695374807%',\n",
       "  'Using: EXPECTED_CLOSE_DATE_DAYS_LAPSED GINI Segmented Model Seg1: 27.958532695374807%',\n",
       "  'Using: EXPECTED_CLOSE_DATE_DAYS_LAPSED GINI Full Model Seg2: 31.471616895345722%',\n",
       "  'Using: EXPECTED_CLOSE_DATE_DAYS_LAPSED GINI Segmented Model Seg2: 31.471616895345722%',\n",
       "  'Using: CUSTOMER_OPEN_DATE_DAYS_LAPSED GINI Full Model Seg1: 22.177527487262005%',\n",
       "  'Using: CUSTOMER_OPEN_DATE_DAYS_LAPSED GINI Segmented Model Seg1: 22.177527487262005%',\n",
       "  'Using: CUSTOMER_OPEN_DATE_DAYS_LAPSED GINI Full Model Seg2: 32.498571700628446%',\n",
       "  'Using: CUSTOMER_OPEN_DATE_DAYS_LAPSED GINI Segmented Model Seg2: 32.498571700628446%'],\n",
       " ['After analysis, we find a good split using: ORIGINAL_BOOKED_AMOUNT set at: 92207.14078562526',\n",
       "  'After analysis, we find a good split using: OUTSTANDING set at: 33228.256089422415',\n",
       "  'After analysis, we find a good split using: BIRTH_DATE set at: 43.65538289376637',\n",
       "  'After analysis, we find a good split using: DOWN_PAYMENT set at: 0.40322744728997456',\n",
       "  'After analysis, we did not find a good split using: REPORTING_DATE_DAYS_LAPSED',\n",
       "  'After analysis, we find a good split using: LOAN_OPEN_DATE_DAYS_LAPSED set at: 2156.21330654391',\n",
       "  'After analysis, we find a good split using: EXPECTED_CLOSE_DATE_DAYS_LAPSED set at: 514.1018082860703',\n",
       "  'After analysis, we find a good split using: CUSTOMER_OPEN_DATE_DAYS_LAPSED set at: 2349.4973676848344'])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.set_train_num(seg_data_cat,target_value,seg_data_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ACCOUNT_NUMBER        BUCKET  CAR_TYPE_AUDI  CAR_TYPE_BAIC  \\\n",
      "count    39319.000000  39319.000000   39319.000000   39319.000000   \n",
      "mean     19806.861136      0.119306       0.000254       0.006028   \n",
      "std      11426.164302      0.324153       0.015946       0.077404   \n",
      "min          1.000000      0.000000       0.000000       0.000000   \n",
      "25%       9917.500000      0.000000       0.000000       0.000000   \n",
      "50%      19818.000000      0.000000       0.000000       0.000000   \n",
      "75%      29681.500000      0.000000       0.000000       0.000000   \n",
      "max      39597.000000      1.000000       1.000000       1.000000   \n",
      "\n",
      "       CAR_TYPE_BMW  CAR_TYPE_BRILLIANCE  CAR_TYPE_BYD  CAR_TYPE_CARRY  \\\n",
      "count  39319.000000         39319.000000  39319.000000    39319.000000   \n",
      "mean       0.003433             0.006638      0.037590        0.000229   \n",
      "std        0.058496             0.081204      0.190205        0.015128   \n",
      "min        0.000000             0.000000      0.000000        0.000000   \n",
      "25%        0.000000             0.000000      0.000000        0.000000   \n",
      "50%        0.000000             0.000000      0.000000        0.000000   \n",
      "75%        0.000000             0.000000      0.000000        0.000000   \n",
      "max        1.000000             1.000000      1.000000        1.000000   \n",
      "\n",
      "       CAR_TYPE_CHANA  CAR_TYPE_CHANGAN  ...  ORIGINAL_BOOKED_AMOUNT  \\\n",
      "count    39319.000000      39319.000000  ...            3.931900e+04   \n",
      "mean         0.001043          0.003357  ...            9.220714e+04   \n",
      "std          0.032275          0.057844  ...            6.048894e+04   \n",
      "min          0.000000          0.000000  ...            1.500000e+04   \n",
      "25%          0.000000          0.000000  ...            5.310000e+04   \n",
      "50%          0.000000          0.000000  ...            7.650000e+04   \n",
      "75%          0.000000          0.000000  ...            1.125000e+05   \n",
      "max          1.000000          1.000000  ...            2.000000e+06   \n",
      "\n",
      "        OUTSTANDING  PROFESSION_ACTIVE  PROFESSION_UNEMPLOYED  \\\n",
      "count  3.931900e+04       39319.000000           39319.000000   \n",
      "mean   3.322826e+04           0.990692               0.009308   \n",
      "std    5.966148e+04           0.096032               0.096032   \n",
      "min   -1.114100e+02           0.000000               0.000000   \n",
      "25%    0.000000e+00           1.000000               0.000000   \n",
      "50%    0.000000e+00           1.000000               0.000000   \n",
      "75%    4.696038e+04           1.000000               0.000000   \n",
      "max    1.350609e+06           1.000000               1.000000   \n",
      "\n",
      "       REPORTING_DATE_DAYS_LAPSED         SEX_F         SEX_M  SEX_UNKNOWN  \\\n",
      "count                39319.000000  39319.000000  39319.000000      39319.0   \n",
      "mean                  1147.572573      0.279966      0.720034          0.0   \n",
      "std                    439.809096      0.448988      0.448988          0.0   \n",
      "min                    738.000000      0.000000      0.000000          0.0   \n",
      "25%                    738.000000      0.000000      0.000000          0.0   \n",
      "50%                   1011.000000      0.000000      1.000000          0.0   \n",
      "75%                   1529.000000      1.000000      1.000000          0.0   \n",
      "max                   2044.000000      1.000000      1.000000          0.0   \n",
      "\n",
      "       TYPE_CORPORATE  TYPE_EMPLOYED  \n",
      "count    39319.000000   39319.000000  \n",
      "mean         0.056003       0.943997  \n",
      "std          0.229931       0.229931  \n",
      "min          0.000000       0.000000  \n",
      "25%          0.000000       1.000000  \n",
      "50%          0.000000       1.000000  \n",
      "75%          0.000000       1.000000  \n",
      "max          1.000000       1.000000  \n",
      "\n",
      "[8 rows x 78 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "file.plot_risk(\"BIRTH_DATE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
